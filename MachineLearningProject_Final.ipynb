{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sys,os\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>558</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Robbins, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Klaber, Mr. Herman</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113028</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mr. Nicholas</td>\n",
       "      <td>male</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112052</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cann, Mr. Ernest Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A./5. 2152</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chapman, Mr. Charles Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248731</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moussa, Mrs. (Mantoura Boulos)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2626</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Leyson, Mr. Robert William Norman</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 29566</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gilinski, Mr. Eliezer</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14973</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>833</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saad, Mr. Amin</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2671</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dean, Mr. Bertram Frank</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2315</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Gee, Mr. Arthur H</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111320</td>\n",
       "      <td>38.5000</td>\n",
       "      <td>E63</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vovk, Mr. Janko</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349252</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Navratil, Master. Michel M</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>230080</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "557          558         0       1                Robbins, Mr. Victor    male   \n",
       "711          712         0       1                 Klaber, Mr. Herman    male   \n",
       "122          123         0       2               Nasser, Mr. Nicholas    male   \n",
       "435          436         1       1          Carter, Miss. Lucile Polk  female   \n",
       "633          634         0       1      Parr, Mr. William Henry Marsh    male   \n",
       "37            38         0       3           Cann, Mr. Ernest Charles    male   \n",
       "695          696         0       2         Chapman, Mr. Charles Henry    male   \n",
       "367          368         1       3     Moussa, Mrs. (Mantoura Boulos)  female   \n",
       "234          235         0       2  Leyson, Mr. Robert William Norman    male   \n",
       "588          589         0       3              Gilinski, Mr. Eliezer    male   \n",
       "832          833         0       3                     Saad, Mr. Amin    male   \n",
       "93            94         0       3            Dean, Mr. Bertram Frank    male   \n",
       "462          463         0       1                  Gee, Mr. Arthur H    male   \n",
       "521          522         0       3                    Vovk, Mr. Janko    male   \n",
       "193          194         1       2         Navratil, Master. Michel M    male   \n",
       "\n",
       "      Age  SibSp  Parch      Ticket      Fare    Cabin Embarked  \n",
       "557   NaN      0      0    PC 17757  227.5250      NaN        C  \n",
       "711   NaN      0      0      113028   26.5500     C124        S  \n",
       "122  32.5      1      0      237736   30.0708      NaN        C  \n",
       "435  14.0      1      2      113760  120.0000  B96 B98        S  \n",
       "633   NaN      0      0      112052    0.0000      NaN        S  \n",
       "37   21.0      0      0  A./5. 2152    8.0500      NaN        S  \n",
       "695  52.0      0      0      248731   13.5000      NaN        S  \n",
       "367   NaN      0      0        2626    7.2292      NaN        C  \n",
       "234  24.0      0      0  C.A. 29566   10.5000      NaN        S  \n",
       "588  22.0      0      0       14973    8.0500      NaN        S  \n",
       "832   NaN      0      0        2671    7.2292      NaN        C  \n",
       "93   26.0      1      2   C.A. 2315   20.5750      NaN        S  \n",
       "462  47.0      0      0      111320   38.5000      E63        S  \n",
       "521  22.0      0      0      349252    7.8958      NaN        S  \n",
       "193   3.0      1      1      230080   26.0000       F2        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in data\n",
    "training_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/train.csv\")\n",
    "training_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data statistics using .describe()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert ages to bins called 'Unknown'for [-1,0], 'Baby' for [0-5],\n",
    "#'Child' for [6-12], 'Teenager' for [13-19], 'Student' for [20-25], 'Young Adult' for [26-35], 'Adult' for [36-60],\n",
    "#'Senior' for [61-100]\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 19, 25, 35, 60, 100)\n",
    "    age_groups = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=age_groups)\n",
    "    df.Age = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method which simplifies the cabin feature by filling N/A values with 'N'\n",
    "#also it takes only the first letter the cabin using splicing\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert fares into bins using the numbers from .describe() statistics earlier\n",
    "#the N/A values are filled with -0.5\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Extraction \n",
    "#the below method is used to extract two features from the Name column\n",
    "#method to format the Name column to extract LName and NamePrefix\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to drop the features which we inconsider inconsequential\n",
    "#we have selected ticket,Name,Embarked columns to be dropped due lack of variance or too many N/A values\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method calls all the above transformation methods one by one and applies it on our dataframe\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to proceed to apply the transformations on the training data\n",
    "transformed_train = transform_features(training_data)\n",
    "transformed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as we can see above our training data now has :\n",
    "#1. LName, NamePrefix instead of 'Name' which has been dropped\n",
    "#2. 'Ticket', 'Name', 'Embarked' have been dropped \n",
    "#3. 'Fare', 'Age' have been converted into convenient bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now as a next step, we need to remember that machine learning algorithms need all the input to be numerical values\n",
    "#But as we can observe from above 'Sex', 'Age' , 'Fare', 'Cabin', 'Lname', 'NamePrefix' are in nominal(string) format\n",
    "#Hence we need to convert these into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>251</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7     73   \n",
       "1            2         1       1    0    0      1      0     3      2    136   \n",
       "2            3         1       3    0    7      0      0     0      7    251   \n",
       "3            4         1       1    0    7      1      0     3      2    198   \n",
       "4            5         0       3    1    7      0      0     1      7     11   \n",
       "\n",
       "   NamePrefix  \n",
       "0          17  \n",
       "1          18  \n",
       "2          14  \n",
       "3          18  \n",
       "4          17  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we proceed to use LabelEncoder from sklearn preprocessing to achieve \n",
    "#Every column in numerical form\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "    return df_train\n",
    "    \n",
    "data_train = encode_features(transformed_train)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we proceed to test the various classifiers in Scikit-Learn to \n",
    "#see which classifiers works best on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "#Below we are splitting up our training data into 80% training , 20% testing data \n",
    "# X contains all the columns except 'Survived' because that is the feature we predict\n",
    "# Y consists only of the column 'Survived'\n",
    "X = data_train.drop(['Survived'], axis=1)\n",
    "Y = data_train.Survived\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 14]\n",
      " [25 43]]\n",
      "0.782122905028\n"
     ]
    }
   ],
   "source": [
    "#Our first classifier will be Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifiers = {}\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "classifiers[\"Decision Tree\"]=dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.508489827856  -  0.555942879499\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.542136709144  -  0.58983623966\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DeepNeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.618025933378  -  0.618025933378\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SupportVectorMachine\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.53073384753  -  0.53073384753\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"MultinomialNaiveBayes\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.714366756092  -  0.714366756092\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LogisticRegression\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.565828303152  -  0.565828303152\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.832630225799  -  0.829813324391\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 500, max_depth = 100)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RandomForest\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.802991281019  -  0.802991281019\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 0.5)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"AdaBoost\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.822791191594  -  0.822810753409\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 100,learning_rate = 0.25)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GradientBoostingClassifier\"]=clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.55364017438  -  0.55364017438\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"Perceptron\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "Decision Tree\n",
      " :  0.757994634474    0.759244355019\n",
      "NeuralNetwork\n",
      " :  0.578763693271    0.537913033758\n",
      "DeepNeuralNetwork\n",
      " :  0.571559915046    0.579874804382\n",
      "SupportVectorMachine\n",
      " :  0.618025933378    0.618025933378\n",
      "MultinomialNaiveBayes\n",
      " :  0.53073384753    0.53073384753\n",
      "LogisticRegression\n",
      " :  0.714366756092    0.714366756092\n",
      "KNN\n",
      " :  0.565828303152    0.565828303152\n",
      "RandomForest\n",
      " :  0.828404873687    0.825606975184\n",
      "AdaBoost\n",
      " :  0.802991281019    0.802991281019\n",
      "GradientBoostingClassifier\n",
      " :  0.822791191594    0.818585401297\n",
      "Perceptron\n",
      " :  0.55364017438    0.55364017438\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hence we see that Random forest classifier gave the best performance with an accuracy ~83% and an F-score ~83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next we proceed to apply \"Feature Scaling\" to see if the performance of our various classifiers improves\n",
    "#Feature scaling aims to bring the values of our numerical features between 0 and 1\n",
    "#This is mainly done because large numerical values may skew our data and make the classifier weight it more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this technique is known to improve the performance of classifiers using gradient descent such as neural nets,perceptron,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = data_train.drop(['Survived'], axis=1)\n",
    "YY = data_train.Survived\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "XX[XX.columns] = scaler.fit_transform(XX[XX.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.110606</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.380303</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.110606   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.206061   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.380303   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.300000   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.016667   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.566667  \n",
       "1    0.600000  \n",
       "2    0.466667  \n",
       "3    0.600000  \n",
       "4    0.566667  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we run the classifiers again after performing feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 13]\n",
      " [24 44]]\n",
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifiers = {}\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "classifiers[\"Decision Tree\"]=dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.786028392578  -  0.780572322826\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.803051084283  -  0.783251732618\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DeepNeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.79598759222  -  0.79598759222\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SupportVectorMachine\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.73565448245  -  0.73565448245\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"MultinomialNaiveBayes\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.79590878605  -  0.79590878605\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LogisticRegression\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.779065504136  -  0.779065504136\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.828365191147  -  0.82985300693\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 500, max_depth = 100)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RandomForest\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.802991281019  -  0.802991281019\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 0.5)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"AdaBoost\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.828485356584  -  0.819974290186\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 100,learning_rate = 0.25)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GradientBoostingClassifier\"]=clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.711349765258  -  0.711349765258\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"Perceptron\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost:\n",
      "Accuracy          F-score\n",
      "0.815669572994  -  0.815669572994\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"XG Boost:\")\n",
    "print(\"Accuracy\"+\"          \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"XGBoost\"]=clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.56%\n",
      "Voting Classifier:\n",
      "Accuracy        F-score\n",
      "0.787516208361  -  0.787516208361\n"
     ]
    }
   ],
   "source": [
    "#Trying the VotingClassifier: tries to concetually combine different machine learning classifiers and use a majority\n",
    "#vote to predict the labels.Such a classifier for a set of equally well performing classifiers in order to balance out\n",
    "#their individual weaknesses.\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "\n",
    "\n",
    "clf1 = clf1.fit(X_train, Y_train)\n",
    "clf2 = clf2.fit(X_train, Y_train)\n",
    "clf3 = clf3.fit(X_train, Y_train)\n",
    "eclf = eclf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = eclf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Voting Classifier:\")\n",
    "print(\"Accuracy\"+\"        \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"VotingClassifier\"]=eclf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "Decision Tree\n",
      " :  0.746704672479    0.756427453611\n",
      "NeuralNetwork\n",
      " :  0.783231052985    0.7874379611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNeuralNetwork\n",
      " :  0.798725128549    0.783271294433\n",
      "SupportVectorMachine\n",
      " :  0.79598759222    0.79598759222\n",
      "MultinomialNaiveBayes\n",
      " :  0.73565448245    0.73565448245\n",
      "LogisticRegression\n",
      " :  0.79590878605    0.79590878605\n",
      "KNN\n",
      " :  0.779065504136    0.779065504136\n",
      "RandomForest\n",
      " :  0.83116253074    0.826916498994\n",
      "AdaBoost\n",
      " :  0.802991281019    0.802991281019\n",
      "GradientBoostingClassifier\n",
      " :  0.824279566287    0.819974290186\n",
      "Perceptron\n",
      " :  0.711349765258    0.711349765258\n",
      "XGBoost\n",
      " :  0.815669572994    0.815669572994\n",
      "VotingClassifier\n",
      " :  0.787516208361    0.787516208361\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So from our results we can see that our best performing classifiers are:\n",
    "#1)RandomForest:  0.835388441762    0.821362061256\n",
    "#2)GradientBoostingClassifier:  0.821363179074    0.824240442656\n",
    "#3)XGBoost:  0.815669572994    0.815669572994\n",
    "#4)DeepNeuralNetwork:  0.803170690812    0.78890509725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next step is to tune the hyperparameters of our best performing classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 14.23 seconds for 100 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.827 (std: 0.023)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 4, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.826 (std: 0.026)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 5, 'min_samples_split': 8}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.822 (std: 0.016)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 7}\n",
      "\n",
      "GridSearchCV took 108.41 seconds for 768 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.834 (std: 0.030)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.831 (std: 0.033)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.830 (std: 0.020)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 100, 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Hyperparameter tuning\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [10,3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3,10,100, None],\n",
    "              \"max_features\": [1, 3,7,10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10,100],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV took 95.87 seconds for 768 candidate parameter settings.\n",
    "Model with rank: 1\n",
    "Mean validation score: 0.829 (std: 0.027)\n",
    "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoost Classifier Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 75.50 seconds for 1536 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'nthread':[1,2,3,4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.01,0.05], #so called `eta` value\n",
    "              'max_depth': [6,8,10,100],\n",
    "              'min_child_weight': [5,10,11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.3,0.7],\n",
    "              'n_estimators': [5,10,20,100], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [27,1337]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV took 68.42 seconds for 1536 candidate parameter settings.\n",
    "Model with rank: 1\n",
    "Mean validation score: 0.815 (std: 0.037)\n",
    "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 1192.61 seconds for 41472 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'nthread':[1,2,3,4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.01,0.05,0.1], #so called `eta` value\n",
    "              'max_depth': [6,8,10,100],\n",
    "              'min_child_weight': [5,10,11,100],\n",
    "              'silent': [1,2],\n",
    "              'subsample': [0.8,0.6],\n",
    "              'colsample_bytree': [0.3,0.7],\n",
    "              'n_estimators': [5,10,20], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999,0,1],\n",
    "              'seed': [27,1337,100]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with rank: 1\n",
    "Mean validation score: 0.808 (std: 0.041)\n",
    "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 34.25 seconds for 150 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.830 (std: 0.023)\n",
      "Parameters: {'max_depth': 8, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.9}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.827 (std: 0.022)\n",
      "Parameters: {'max_depth': 12, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.826 (std: 0.026)\n",
      "Parameters: {'max_depth': 8, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.85}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'max_depth':range(6,16,2),\n",
    "              'min_samples_split':range(100,999,150),\n",
    "              'min_samples_leaf':range(20,77,100),\n",
    "              'max_features':range(7,20,100),\n",
    "              'subsample':[0.6,0.75,0.8,0.85,0.9]}\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with rank: 1\n",
    "Mean validation score: 0.830 (std: 0.011)\n",
    "Parameters: {'max_depth': 14, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plotting ROC curves for our best classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIMlBCCFECZIchBBClPB/SjkwW7z0yOAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112468908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ROC Curve for Random Forest Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    " \n",
    "# shuffle and split training and test sets\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size=.25)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "#clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'gini')\n",
    "#rf_clf = clf.fit(X_train,Y_train)\n",
    "#rf_predict = rf_clf.predict(X_test)\n",
    "\n",
    "forest.fit(X_train, Y_train)\n",
    " \n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, forest.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4U9Ufx/F3ugstq5Q9ZRw2yBAEZDpAhoAoMlQQlK3M\nIlaQDWUJqPwUHChO3AsHiIAslSEi4NGKyhIopXuP/P5IKIWudKS3Sb6v5+Fpcu/NzaeH9H5z1zkm\ns9mMEEIIkZmb0QGEEEKUPFIchBBCZCHFQQghRBZSHIQQQmQhxUEIIUQWUhyEEEJk4WF0ACGKilLK\nDPwGpAFmoBQQDYzXWh+0LlMamA/0A5Kty30OLNJaJ2Ra18PAOMAX8AL2AEFa68gc3jtfywtR0sme\ng3A23bXWrbTWN2utFfAe8ByAUsoD2I7lc3+z1ro50AHwA76xzkcp9RQwBhigtW4FtARSsBSRLPK7\nvBCOwCQ3wQlnYd1zCNRaX7Y+9wBWA/W01n2UUkOBKVrr9je8zgQcARYDW4GLWIrHn5mWKQUMBN7X\nWidnml46r+WBp4CKWutJ1nnzrj5XSu0ErgCNgJeAOUA1rXWyUsod+Be4EzgHrAWaA57Ad8BMrXVq\noRtOiGzInoNwNt8rpY4qpc4Df1injbL+7AjsvvEFWmszlo1tZywb6fjMG3rrMvFa67cyFwar/C6f\nnQitdROt9VrgONDfOv1O4B+t9QngWeCQ1roNcDNQEZhmw7qFKBApDsLZdNdatwT6YDnnsE9rfSnT\nfM8cXueN5fxDOvn7u8jv8tn5IdPjjcBI6+NRwMvWx32BsUqpX4BDwC1Y9iKEsAspDsIpaa2PAFOB\nl5VSdayT9wJdlFLXfe6tz7sA+4ATgKdSqv4Ny/gopbYqpard8Fa2LG8GTJlme92wjthMjz8A2iul\nGgNdgS3W6e7AfdbzKa2A9sCkXBtBiEKQ4iCcltb6HWA/sMY66QMgDlijlPIFsP58DssG+mOtdRIQ\nAryqlKpsXcYby2Gd0lrr8ze8hy3LhwFtlFIm6zmKO3PJnAi8C2wCPtRax1tnfQNMta7DG/gMKQ7C\njqQ4CGc3CeitlLrLevL2TiyF4JBS6jfgsPX5HVrrFACt9RLgQyxXMP0CHMXyzf+e7N7AhuXfwlIg\n/sRywnt/Hpk3Yjls9HKmaY8DpYFjwK/Wn8ttbAMh8k2uVhJCCJGF7DkIIYTIQoqDEEKILKQ4CCGE\nyEKKgxBCiCwcpuO91NQ0c0REfN4LuoDy5UshbWEhbXGNtMU10hbXBAb6m/JeKiuH2XPw8HA3OkKJ\nIW1xjbTFNdIW10hbFJ7DFAchhBDFR4qDEEKILKQ4CCGEyEKKgxBCiCykOAghhMhCioMQQogs7Foc\nlFLtrcMg3ji9n1LqZ6XUfqXUo/bMIIQQIv/sdhOcUioIeBBL//mZp3ti6eu+nXXeXqXUZ1rri/bK\nIoQQJVVUXDJxCSl2WbfZbCYw0L9Ar7XnHdJ/AYOAzTdMbwyEaq0jAJRSe7CMwvW+HbMIIUSJcyki\nntkbDlDUIyeYzemc+e07zhz/jivnThZoHXYrDlrrDzMNz5hZGSAq0/MYoKwt6yxoBXRG0hbXSFtc\nI21xjSO0xaWYZMxmuKl6WVSt8kWyznP//sm7GxdxSh/F26dUgddjRN9K0UDm/zV/INKWF4aFxdgl\nkKMJDPSXtrCStrhG2uIae7fFqfPRrP3gKEkpaYVaT3q65WeT2uUY1OWmIkgG998/jVP6KP36DWDR\nomUFXo8RxeEk0EApVQHL8IxdgJUG5BBCiAI5fTGGmPgUKpb1wc/Xs1Dr8vBwo2X9ioVax8mTJ2jc\nuAkAS5eu4O+/T3H77XcVLlehXp0PSqlhgJ/WeoNSahqWAdPdgFe11ueKK4cQQhTU+ztD+etcNJGx\nSQAM6noTHZpUMSzP+fPneOqpIL766gu2bt1OmzbtqFevAfXqNSj0uu1aHLTW/wAdrI/fzjT9c+Bz\ne763EEIUta8OnM547OvtQbWA0obkSE1N5eWXXyQkZAlxcbF06NCRMmVsOnVrM4cZz0EIUbLtPHKO\nC1dKxhgKpUp5ER+fbJd1N6xZjieHt7bLum1x6NDPzJgxhePHj1GhQgWWLFnPAw8Mx2Qq0LANOZLi\nIIQotNiEFN74Rhsdo1iU8/My9P0/+eQjjh8/xtChI5g7dyEBAQF2eR8pDkKUcHGJKRz/+wrpeVwM\nX8Y/iuiYhGJKdb2ExFQAmtYpz73d6hmSIbPy5UoTERmX94IFUL2in13WmxOz2cx3331Ljx534Obm\nxqxZwfTp048OHTra9X2lOAhRwn36w99sP3TW6Bg2qVDGhzpVyhgdw3Ipq4/jjwZ36lQoQUHT2b37\ne1atWseDD47Ez8/P7oUBpDgIUeIlJFu+lQ/schP+uVw26efvQ2xMYnHFysJkotCXZAqLpKQk1q1b\nzbp1q0lKSqJnzzu47bauxZpBioMQDqJDk8oElvPNcb7cBOcc9u3bw/Tpj/PXX6FUqVKVxYtD6Nv3\nniI/4ZwXKQ5CCFGCnDlzmr//PsVjj41n1qxg/P2NOUwnxUGIEig2IYXFbxwkOj6Z5JR0o+MIO0pP\nT+fdd9+iT59+lC1bjvvvH0qrVq1RqpGhuWSwHyFKoIsR8VyMSMDD3Y3qFUvTumEgFcp4Gx1LFLHf\nfjtGnz53MGXKRFautPSDZDKZDC8MIHsOQpRonZtX5b7u9Y2OIYpYbGwsK1YsZcOG9aSlpTFgwCAm\nTnzC6FjXkeIghBDFaO/eH5g0aSznzp2ldu06hISsokePO4yOlYUUByGKUHxiKtsPnSEpuXBdOV/t\n2E04H39/f65cCWfatJk88cQMfH1zvgLNSFIchChCR0Mv88kPfxfZ+sqUNrarBlF4KSkpbNjwP3r0\nuJ3GjZvQokUrDh8+YbduL4qKFAfhciJjk/jzbFTeCxbAn+cs6+3fqQ7N6xXuj9/DzY2alYu3qwZR\ntH766UdmzpzCyZPH+fHH/bzxxjsAJb4wgBQH4WL06Qie/+gYcda+gOylRqAf9aoVbRfKwnFERFxh\n0aL5bN78GgAjRjzM00/PMzZUPklxEE4tJTWNyFhL180n/41gs7Xn0H4d69jtkI2Pl7t0I+HCfvrp\nR0aOHMrly5dp3LgJy5evoX37DkbHyjcpDsKpLdl8mH8vXutSorSPBxMHNqdR7aIZzF2IG9WvXx8f\nH1/mzFnAuHET8fQs3DCiRpHiIJza5agESnl7cHPDinh5unNn25pUrlDK6FjCiSQmJrJ27SqaNGlG\nv373UKFCAAcOHMHLy7EvJpDiIBzOpcgEVr17hPjEVNzcTKSn5zzOQVxiKjUCSzO6T5NiTChcxc6d\nO5g1axp//32K1q3b0Ldvf0wmk8MXBpDiIBzQ2UuxhEUmUra0F+X8vUlNy7nvoXL+3nRsVrUY0wlX\ncPHiRZ55ZjYfffQB7u7ujBs3iaCg2cXec6o9SXEQ+bJlRyhnwmINzRAdZznB3LtDbYbf3US6qRbF\n6uTJE/TrdxfR0VG0bt2GFSvW0rx5C6NjFTkpDsJmicmpfP3TaaNjAODhbqJ6YGmjYwgX1LChomXL\nm+nbtz8PPTQKd3fHH3EuO1IchM2uDmHc/KYAJg1qbmgWkwk83KVTYWF/sbExhIQspnRpP5588mnc\n3d354INPneoQUnakOIh8czOBp4dsmIVzM5vNfPnl5wQHB/Hff+dRqhHTpgXh5eXl9IUBpDgIIDUt\nnd//jSApj0FlUlIL15mcEI7i9Ol/mT17Btu2fYOXlxczZjzJ449Pc4qrkGwlxUHw44mLvPLlSZuX\n9/J0zmOsQgBcvHiBLl3aEx8fz223dSUkZDX16zcwOlaxk+LgIhKSUklIyr4/obDIBAA6t6hKzcA8\nOnozwc3SNYRwQqmpqXh4eFC5chVGjhxD06bNGDx4iEscQsqOFAcXcCU6kSdf2k9qWs43iwHc3KAi\nNzcILKZUQpQMV66Es3DhM1y6dJE339yCyWRi3rxFRscynBQHFxARk0RqmplqFUtTO4cuoEt5e9Ko\nlvQ3JFyH2WzmvffeZv78pwkPD6dJk2ZERkZQvnwFo6OVCFIcnNiHu/7ih6PnM/YYWtYP4L5uMh6x\nEH/8oQkKmsq+fXsoVaoU8+Yt5rHHxuPhIZvEq6QlnNjR0HBi4lOoElCKCmV8aHFTyR9gRAh7i4+P\np3//u7hy5Qq9evVhyZLl1KhR0+hYJY4UBwcWejaKL/f/Q079zoVFJeDr7cHiRx2vL3khilpkZATl\nypXP2FMoW7YcvXv3MTpWiSXFwYHt/e0/jv4VnusyjWqVK6Y0QpRMFy78x5w5szl69Ai7dh3A19eX\nBx4YbnSsEs9uxUEp5QasB1oCScAYrXVopvnDgelAGvCq1vp/9sriqBKSUtl55ByJydfffFaqtBfx\nccn8/V80APNGtctxjAK5k1m4qrS0NF57bSNLliwkNjaGtm1v4cqVcKpXr2F0NIdgzz2HAYCP1vpW\npVQHYBVwT6b5K4GmQCxwQin1rtY6wo55HM4vf17m/Z1/5bqMyWTpltpbbkwTIsOhQ4cYPfpRjh49\nQtmy5Vi5ci0jRjyMm5t8WbKVPYtDZ+BrAK31AaVU2xvm/wqUBVIBE5D7RfhOJDo+mb/OReW53Knz\nlj2DPrfWplnda5fXlStXisjIeMtjf2/KlHKdW/qFyEt6ejoPP/wwx48f5777HmDevMUEBsr9O/ll\nz+JQBsi8BUxTSnlora/epvsbcAiIAz7SWkfmtcLAQP+iT2mA9S8f4ODJizYv37xBJTq1rGbHRI7N\nWT4XRcFV28JsNhMaGkqDBpZuLjZs2EBiYiI9evQwOJnjsmdxiAYyf1LdrhYGpVQLoA9QF8thpTeV\nUvdprd/PbYWOOKhLalo6MfEp1027HBGPCbi/R973HPh4uVO3UqnrfvfAQH+HbAt7kLa4xlXb4p9/\n/mb27Bns27eHH374iVq1atOxY0fCwmJcsj1uVNAvDPYsDnuBfsAW6zmHY5nmRQEJQILWOk0pdQlw\nyttzF75+kDOXso6c5uFu4q5bahmQSAjnkJyczPr161i9ejmJiYl06dLd6EhOxZ7F4WPgDqXUPizn\nFEYppYYBflrrDUqpl4A9Sqlk4C9gkx2zGOZiRDylfTxodsMNaPWqlTEokRCOb//+vcycOYU//tAE\nBlZizZoXGDhwsMt2kmcPdisOWut0YNwNk3/PNP9F4EV7vb+Rfgm9zFvfalLTzSSnpFMtoDRj+zc1\nOpYQTmPDhv/x559/MGrUGJ56ai5ly8r9PEVNruuyg9//jSA8Ogl3NxOVy/tyS+PKRkcSwqGlp6ez\nZ8/ujOeLF4ewdet2QkJWS2GwE7lD2o4mD2pB7SquefWIEEXl999PEhQ0lQMH9rFlyyd069aDatWq\nU61adaOjOTUpDkKIEik+Pp7Vq5ezfv06UlNT6dOnPw0bKqNjuQwpDkVoz6//cSU60aYb3IQQOfvu\nu2+ZNWs6p0//S82atVi6dAV33tnb6FguRYpDEbkclcCrW68fh7m0rzSvEAVx5Mhhzp8/x+TJU5k2\nLYjSpUsbHcnlyNariFwdUKdFvQDualeTMn7eVCzra3AqIRxDamoq77//LoMHD8HT05PJk6fSt+89\nNGrU2OhoLkuKQxEr5+dN4zoyzKAQtjp8+CAzZ07l2LGjREVFMm7cJLy9vaUwGEyKQyGZzWZi4lOI\nTUjJe2EhRIbo6CiWLFnAa6+9jNlsZsiQYQwe/IDRsYSVTcVBKVUaqIelC4xSWus4u6ZyIJu//YOd\nR85lPHeTGzSFyNM333zF9OmPc+nSRRo0aMjy5c/SqdNtRscSmeR5E5xSqidwFPgUqAL8o5S6097B\nHMWFcEudbKsCuaVxJW6T3lOFyJPZbCY6OorZs+fw/ff7pDCUQLbsOSzBMjbDV1rr/5RSXYF3gG/t\nmszBjB/QTPp1ESIHSUlJvPji8wwd+iCVKlWiV6+7+fnnX6lcuYrR0UQObOk+w01rfeHqE631CTvm\nEUI4mT17dtO9e0cWL57PqlXLMqZLYSjZbNlzOKuU6guYlVLlgInAafvGEkI4urCwMObNC+b999/F\nZDIxevRjzJ49x+hYwka2FIexwFqgJpautXcAj9ozlBDCsW3f/g0TJjxKZGQkLVq0YuXKNbRq1dro\nWCIfbCkOLbXWQzNPUEoNAj6yT6SSLyU1jd1H/yMhKZXLUYlGxxGixKlb9ybc3d1ZvDiERx55DHd3\nd6MjiXzKsTgopYYA3sACpdTcG17zFC5cHH47dYW3tv2R8by0j9wuIlxbXFwcK1cuo0+ffrRtewv1\n6jXg8OET+PpKLwGOKretWhmgI5ZxoDOPv5cKBNszVEmXkpYOQM/WNWjZIIDK5UvJlUrCZX3zzVfM\nnj2Ds2fP8NdfobzxxjsAUhgcXI7FQWu9EdiolOqptf6uGDM5jGoVS9GsbkDeCwrhhM6dO8tTTwXx\n1Vdf4OHhwRNPTGfq1JlGxxJFxJbjIUlKqU8BPyxjQbsDtbXWdewZzGgpqekkpaRlOy8xOfvpQriK\nffv2MGzYfcTHx9GhQ0eWL39W+kJyMrYUh5eBEGAksA7oDRy2YybDJSanMuvF/cTE595fkhxKEq6q\nRYtW1KtXnzFjxvLAA8Plb8EJ2VIcErTWryml6gARWC5jPWTXVAaLjU8hJj6FCmW8qVOlTLbLeHu6\n0aKeHFISriEqKpLFi+fTokUrRox4GD8/P7Zv3y1FwYnZUhwSlVIVAA100FrvsHbE5/Qa1yrP6L5N\njI4hhGHMZjMfffQ+c+c+RVjYJdq3v5Xhwx/CZDJJYXBytnSfsRp4D/gceEgpdRwn33MQQsBff/3J\n4MH3MH78GGJjY3j66Xl8+OHnUhRcRJ57Dlrr95VSH2itzUqpNkBDINT+0YpHfGIKW77/i/ik1Ixp\nyTmciBbCVZw4cZw77+xKcnIyPXvewbJlq6hdu47RsUQxyu0muEBgGnAFeBbL/Q0JWO59+BqoXBwB\n7U2fjmT30fPZzqsSUKqY0whhrPT0dNzc3GjcuAn9+g3g7rv70bdvf9lbcEG57Tm8BcQAFQEvpdRW\nYDNQCphaDNmKRbpl6GcG3laXrq2qZ0x3czPh5+tpUCohitelS5eYNy8Yf39/QkJWYzKZ+N//XjY6\nljBQbsWhnta6nlLKH9gPTACeA1ZrrZOLJV0x8vHyoExpL6NjCFGs0tPT2bx5E4sWzSMqKpLWrduQ\nnJyMl5f8Lbi63IpDNIDWOsZ6tdK9Wuv9xRPLPtLS0zl1PprU1PSMaWfDYg1MJIRxfvvtGDNnTuHQ\noZ/x8/Nn6dIVjBw5RjrJE0DuxcGc6fFFRy8MADsOn+Od7X9mO8/Dw5YLt4RwDhcvXqR37x4kJSUx\nYMAgFixYSpUqVY2OJUqQ3IqDv1LqNiyXu5a2Ps44K6W13m3vcEUlNS2dlNR0ImOSAOjcvCoVy/pk\nzPfydKd940pGxROi2MTGxuLn50flypUJCgqmadOm9Ohxh9GxRAmUW3E4CyywPj6X6TFY9ip62CtU\nUUpJTWPWi/uJjL12mqRzi6o0rFnOwFRCFK8zZ04THBzElStX+Oyzr3Fzc2Py5ClGxxIlWG69snbP\naZ4jiU1IJTI2mXJ+XtSpUga/Up7UqeJvdCwhikVKSgobNvyPFSuWEB8fT8eOnYmKiqR8+QpGRxMl\nnMuMUqNqlWds/6ZGxxCi2Pz884/MnDmVEyd+IyAggJCQ1dx//1C5Z0HYxGWKgxCuJCEhgYcfHsbl\ny2GMGPEwTz89jwoVpKNIYTu7FQellBuwHmgJJAFjtNahmea3w9Jvkwm4AIzQWsuAzEIUkNls5uzZ\nM9SoURNfX19Wr36OcuXK06HDrUZHEw4oz+s3lVLllVIblVI7lFIBSqlXlVLlbVj3AMBHa30r8CSw\nKtM6TcBGYJTWujOW7jhqF+xXEEKEhv5Jz5496d27J9HRUQD06nW3FAZRYLZc3L8R+BkIwNKdxn/A\nmza87upGH631AaBtpnkNgXBgqlJqF1BBa63zkVsIASQmJhISsphu3W7l+++/p2XLViQkyA64KDxb\nDivV1VpvUEqNt3abEayUOmrD68oAUZmepymlPLTWqVj6a+oITMLSw+sXSqmDWusdua0wMDD/Vxm5\neVl+RW9vjwK9vqRypt+lsFy1LbZt28aECRMIDQ2levXqPPfccwwYMEBOOFu56ueiqNhSHFKVUmWx\n3jGtlGoApOf+EsDS/Ubm/x03a2EAy15DqNb6pHWdX2PZs8i1OISFxdjwtteLsN74lpSUWqDXl0SB\ngf5O87sUlqu2hdlsJihoFqdOnWLs2InMmvUUdetWc8m2yI6rfi6yU9AiaUtxeAbYCdRSSn0C3Ao8\nYsPr9gL9gC1KqQ7AsUzzTgF+Sqn61pPUtwGv5Ce4EK4mLS2NX345TJs27TCZTKxZs560tFSaN29p\ndDThhGwpDtuAg0B7wB0Yq7W+aMPrPgbuUErtw3JF0iil1DDAz3qYajTwtvXk9D6t9ZcF+xWEcH7H\njh1l5swp/PrrUXbs2EujRo1p0kTu2xH2Y0txOI1lQ/+m9cSyTbTW6cC4Gyb/nmn+DuAWW9cnhCuK\njY0hJGQxGze+SHp6OoMG3Sd3N4tiYUtxaAbcCyxWSlUH3sVSKJxmqFAhSqIvvviM4OAg/vvvPHXr\n3kRIyGq6dXOILs2EE7BlDOkI4GXgZaVUW+Al4GlbXiuEKLht274mPPwyM2Y8yeOPT8PHxyfvFwlR\nRPLcwFvHkr4PeACoALwNDLRzLiFcTkpKCl988SkDBtyLyWRi7tyFTJ48lfr1GxgdTbggW779/wJs\nAaZqrQ/ZOY8QLunAgf0EBU3h999P4uHhSb9+9xAQEEBAgPSHJIxhS3GoaT25LIQoYleuhLNw4TO8\n9dYbADz00CPcdlsXg1MJkUtxUEod1lq3xnITXOYhQ02AWWstA80KUQgff/wBTz01k/DwcBo3bsrK\nlWto16690bGEAHIf7Ke19WeW/peUUt72DCWEK7h8OYyEhATmzVvMo4+Ow9PT0+hIQmSwpVfW/Tc8\nd8NyU5wQIh8SEhJYt+5ZEhISAHjkkcfYt+8QEyZMlsIgSpzcDivtALpZH2c+55AKfGbfWEI4lx07\ntjFr1nT+/fcfzOZ0nnhiOu7u7lSrVt3oaEJkK7fDSj0AlFJrtdZPFF8kIZzHhQv/MWfObD799CPc\n3d2ZMOFxRo8ea3QsIfKU255DX631F8BhpdRDN87XWr9h12RCOLiPP/6AGTOmEBMTTdu2t7BixRqa\nNm1mdCwhbJLbpaztgC+wHlq6gRmQ4iBELipXroK7uxsrV65lxIiHcXOzZWwtIUqG3A4rPWP9Oerq\nNKVUGSz3PRwvhmxCOJSYmGiWL1/KmDFjqV27Dh07dubw4eP4+cmgM8Lx2NJ9xmigEzALOALEKKU+\n1Fo/be9wQjgCs9nM559/QnDwLC5evEBiYiIrVjwLIIVBOCxb9nMnADOAocCnQHOglz1DCeEo/vnn\nb4YNG8yYMQ8TGRlBUNBTLFq0zOhYQhSaTQdBtdZXgLuBL61DffraNZUQDuDLLz+nS5f2fPfdNrp0\n6c6uXfuZMeNJvL3lHlHh+GzpW+m4UuoL4CZgu1JqC/CzfWMVXnhUIr/+dZm4xNS8FxaiAG6+uTVV\nq1Zj1qxgBg4cjMlkMjqSEEXGluLwCNAROKa1TlZKbQa+sm+swnt/Zyg/nbyU8dzXW4afEIUTHh7O\nggVzGDDgXrp370m1atXZt+8Q7u7SzZhwPrZsMb2AvsBqpZQH8D2wA8ud0iVWUnIaAKP7NMbb053G\ndcobnEg4qvT0dN599y3mz3+aiIgIYmJi6N69J4AUBuG0bCkOzwPxWPYgTMCjwIvAg3bMVWRaNwyU\nvQZRYL//fpKgoKkcOLCP0qX9WLhwqdzhLFyCLVvNNlrrlpmeT1JKnbBXoMIym82YsdylJ0Rh/PDD\nLoYMGUhqaip9+vRn8eIQ6QtJuAxbioObUqqc1joSQClVjhJ6SOnilXgWvH6QhKQSGU84CLPZjMlk\n4pZbOnDbbV0ZPfox7ryzt9GxhChWthSH1cDPSqmrPbH2B5baL1LBXbgST0JSKoHlfAgo40ONSn5y\nSEnY7Pz5cwQHz6JNm3ZMmvQE3t7evPfex0bHEsIQeW45tdavKaV+BrpiuS9ikNb6mN2TFUK3m6vT\nu31to2MIB5Gamsqrr25g6dJFxMXFEhcXy8SJj8ulqcKl5dYrqxswEWgI7NFav1BsqYQoJkeOHGLG\njCkcO3aU8uXLs2jR8wwdOkIKg3B5ud0hvR64D4gDnlJKzS2eSEIUj5MnT9CrVw+OHTvKkCHD2Lv3\nEMOHPyS9pwpB7oeVugJNtNZmpdQKLPc2LCieWELYh9lsJjExEV9fXxo3bsLYsRO5667edOp0m9HR\nhChRcvuKlKi1NgNorcORq0OFgzt16i+GDBnI1KmTMqYtWLBECoMQ2citONxYDNKzXUqIEi4pKYlV\nq0Lo2rUDO3fuICLiCklJSUbHEqJEy+2wUm2l1Ks5PddaP2K/WEIUjT17dhMUNJXQ0D+pVKkyixeH\n0L//QDnhLEQecisO0254vsueQYQoapcuXWLo0HtJTk5m9OjHmD17DmXKlDU6lhAOIbdhQl8vziBC\nFIX09HTCwsKoXLkylSpVIiRkNU2aNKVVq9ZGRxPCocjtw8JpnDhxnJkzpxAbG8v27bvx9PRk2DCH\n6B9SiBLHbsXBehPdeqAlkASM0VqHZrPcBuCK1vpJe2URzi0uLo6VK5fx4ovPk5aWRv/+A4mPj6Ns\n2XJGRxPCYdlUHJRSpYF6wDGglNY6zoaXDQB8tNa3KqU6AKuAe25Y71gsY1LL+QxRIJ9//jkTJkzk\n7Nkz1KpVh2XLVnD77XcZHUsIh5fnraBKqZ7AUeBToArwj1LqThvW3Rn4GkBrfQBoe8N6OwLtgZfy\nmVkIABITE5k4cSIXL15gypQZ7N59QAqDEEXElj2HJVg29F9prf9TSnUF3gG+zeN1ZYCoTM/TlFIe\nWutUpVT0KRrcAAAbs0lEQVRV4BlgIHC/rWEDA/1znV82zLJD41faO89lHZ2z/345SU1N5cSJE7Ro\n0QLw580336RixYo0adLE6Gglgqt+LrIjbVE4No3noLW+oJQCQGt94urjPEQDmf933LTWVwdauA+o\nCGzFsjdSSin1u9Z6U24rDAuLyfUNo6ISAIiNS8pzWUcWGOjv1L9fTg4e/ImZM6dy9uwZ9u49SKVK\nlejSpQthYTEu2R43ctXPRXakLa4paJG0pTicVUr1BczWgX4mAqdteN1eoB+wxXrOIaObb631OmAd\ngFJqJNAor8KQm3NhsZw6H82ZS7EFXYUowSIjI1i8eAFvvPEqZrOZYcMexNNTLrQTwp5s+QsbC6wF\nagKngO+Ax2x43cfAHUqpfVjGnh6llBoG+GmtNxQwb7Ze+Pg3LlyJz3ju4yUbDmdgNpv56KP3mTNn\nNpcvh6FUI1asWEOHDh2NjiaE07NlsJ9LwND8rlhrnQ6Mu2Hy79kstym/6wbLhuNiRAIpqenEJabg\nX8qT+7vXx8vTnZb1AgqySlECvf32ZuLiYnn66XmMGzcJLy8voyMJ4RLyLA5Kqb/JpkdWrfVNdklk\noz3H/uO1rddqTdWAUnRqXtXARKIoJCYm8sMPO7njjl6YTCZWrVqHyWSidu06RkcTwqXYcvylW6bH\nnliuMPK2S5p8iIyx9Kp5c4OKVCjjQ/ObZG/B0e3a9T2zZk3j779PsXXrdtq0aUedOnWNjiWES7Ll\nsNK/N0xaoZQ6CCyyT6T86dGmBk3rVDA6hiiES5cuMXfubD766H3c3Nx49NFxNGxo0xVxQgg7seWw\nUpdMT01AU8DXbomES9m8eRPz588hOjqKVq1uZuXKtbRo0croWEK4PFsOK83P9NgMXAYetk8c4Wr+\n+ENjNptZunQlI0eOxt3d3ehIQghsKw5btNb/s3sS4RJiY2N5++03GDNmHG5ubsyaFcykSU9QuXIV\no6MJITLJs28lLDe9CVFoW7d+QefO7Xj66Sf54IP3APDz85PCIEQJZMuewxml1A7gRyDh6kSt9QK7\npRJO5cyZ0wQHB/H111vx9PRk2rQg+vUbYHQsIUQubCkOBzI9loF3Rb68/vqrPPPMU8THx9Op020s\nX/4sDRo0NDqWECIPORYHpdTDWuvXtdbzc1pGiLz4+Pjg6+tLSMhq7r9/KCaTfL8QwhHkds7hiWJL\nIZxGRMQV5s59iqioSADuv38oBw4cYciQYVIYhHAgtpyQFiJPZrOZLVveoVOntrz44vO8/LJlDCeT\nySTDdQrhgHI759BUKXUqm+kmwGx030qi5AgN/ZOgoKns2bObUqVKMXfuQsaOnWB0LCFEIeRWHEKB\nu4sriHBMb7+9maCgqSQnJ3PXXb1ZsmQFNWvWMjqWEKKQcisOydn0qyTEdZo1a06VKlVZsGApvXv3\nkfMKQjiJ3M457C22FMJhXLx4gfHjx3Dy5AkAWrRoxYEDR7j77r5SGIRwIjkWB631pOIMIkq2tLQ0\nXn11Ix07tuXDD7ewadPLGfM8PGTkPSGcjfxVizz9+usvzJw5hSNHDlOmTFmWL3+WBx8caXQsIYQd\nSXEQufrkkw8ZN2406enpDBp0H/PnL6Fy5cpGxxJC2JkUB5GF2WwZFdZkMtGlSzdat27LrFnBdO3a\n3eBkQojiIjfBiev8++8/DB9+H5999jEAFSoEsHXrdikMQrgYhysO8Ykp/BceR0x8itFRnEpKSgrr\n1q2mS5f2bN/+Ld9885XRkYQQBnKow0opqWkE/W8/8UmpGdPc5fLJQjtwYD9BQVP4/feTVKwYyKpV\n67j33vuNjiWEMJBDFYfE5DTik1KpWNaHpnUr4OfrSb3qZY2O5dB2797J4MH9MZlMPPzwaIKD51Ku\nXHmjYwkhDOZQxeGq2lX8ebhXI6NjOCyz2Uxqaiqenp506nQbQ4YM4+GHH6Ft21uMjiaEKCEc7pyD\nKBytf2fAgLtZsWIpAO7u7jz33ItSGIQQ13HIPQeRf/Hx8axZs5IXXlhLSkoKgYGVMJvN0uWFECJb\nUhxcwI4d2wgKms7p0/9Qo0ZNlixZQa9e0uGuECJnUhycnNa/88AD9+Lu7s7EiU8wffos/Pz8jI4l\nhCjhpDg4obS0NGJioilXrjxKNWLOnAX06HE7TZs2MzqaEMJByAlpJ/PLL4fp1asH48ePyegGY/Lk\nKVIYhBD5IsXBSURHRzF79gzuuqs7R48eoUKFAJKSkoyOJYRwUHJYycGZzWY+++xjnn76SS5evED9\n+g1YvvxZOnfuYnQ0IYQDk+Lg4MLDw5kyZRKpqSnMmhXMpElT8Pb2NjqWEMLB2a04KKXcgPVASyAJ\nGKO1Ds00fygwBUgFjgETtNbp9srjTJKTkzl1KpSbbqpPxYoVWb9+I0o14qab6hkdTQjhJOx5zmEA\n4KO1vhV4Elh1dYZSyhdYBHTXWncCygJ97ZjFaezbt4dWrVoxZMggEhISAOjdu48UBiFEkbLnYaXO\nwNcAWusDSqm2meYlAR211vGZciTmtcKAAMv1+d7eHgQG+hdt2hIuLCyMmTNn8vrrr2MymZgwYQLl\ny/vi7+9a7ZAdV/ss5Eba4hppi8KxZ3EoA0Rlep6mlPLQWqdaDx9dBFBKTQb8gG15rTA8PBaApKRU\nwsJiij5xCZSens4777zJggVziIiIoFmzFrzyykbq1m1MYiIkJrpGO+QkMNDfZT4LeZG2uEba4pqC\nFkl7FodoIHMqN611xkAM1nMSy4GGwL1aa7Mdszis1NRU1q9fR3JyCgsXLmX06LFUrVpePvhCCLuy\nZ3HYC/QDtiilOmA56ZzZS1gOLw2QE9HXi4uL4+jRI3Ts2BkvLy9efPFVAgICqFatutHRhBAuwp7F\n4WPgDqXUPsAEjFJKDcNyCOkgMBr4AdihlAJYq7X+2I55HMK2bV/z5JMzuHw5jB9++IlatWrTvHkL\no2MJIVyM3YqDdW9g3A2Tf8/0WO7OzuT8+XMEB8/iyy8/w8PDgwkTHqdixUCjYwkhXJTcBGcws9nM\nhg3rWbZsMXFxsbRvfysrVqyhUaPGRkcTQrgwKQ4GM5lMHDiwHy8vTxYvfoEHHhiOm5vsVAkhjCXF\nwQBRUZFs3foFQ4eOAGDZslW4u7tTsWJFg5MJIYSFFIdiZDab+eSTD5kzZzaXLl2kZs1adO7chcqV\nKxsdTQghriPFoZicOvUXs2ZNY9eu7/Hx8eGpp+Zyyy0djI4lhBDZkuJQDJ57bg3Lly8mKSmJHj1u\nZ9myVdSpU9foWEIIkSMpDsUgKSmRcuXKs3hxCP36DcBkMhkdSQghciWXxdhBWFgYixfPJyUlBYDJ\nk6eyd+/P9O8/UAqDEMIhSHEoQunp6WzevIlOndqwdu0q3n//XQC8vb0pU6aswemEEMJ2clipiBw/\n/hszZ07h4MGf8PPzZ+nSFQwZMszoWEIIUSBSHIrACy+sY9GiZ0hLS6N//4EsWrSMKlWqGh1LCCEK\nTIpDEahXrz7Vq9ckJGQlPXveaXQcIYQoNDnnUABnz55h/PgxXLp0CYBeve5m796fpTAIIZyGFId8\nSElJYf365+jc+RY+/HALb765KWOet7e3ccGEEKKIyWElGx08+BMzZkzhxInfqFChAsuWrZQTzkII\npyV7DjZ45ZUN9OlzBydO/Mbw4Q+xb98hHnhguNyzIIRwWrLnYINu3brTokUrFi5cRocOtxodRwgh\n7E72HLIRGvongwffw88//whAvXoN+PbbnVIYhBAuQ4pDJomJiYSELKZbt1vZvft7Pvvsk4x5cghJ\nCOFK5LCS1a5d3xMUNJW//z5FlSpVWbx4OX379jc6lhDF4vDhg8ydO5s6depiMpmIi4ujWrXqPPPM\nIjw9PYmIiOCFF9Zw4cJ/pKenU6lSZSZPnkpAgGWAqqNHj/DaaxtJTU0lMTGRu+/ux6BB9xn6O0VF\nRfLSSy8QFBRsaI6kpEQWLJhDREQEpUqVIjh4PuXLl79umXfeeZNt277Gzc2NBx8cRdeu3dm8eRM/\n/rgPgNjYWK5cCeezz77hlVdeokePO6hb9ya75pbiAHzwwXtMmPAobm5ujB07gVmzgvHz8zc6lnBR\nW3aE8vPvl/L9Ond3E2lp5mzntWtUift71M/19W3atGX+/KUZz+fNC2bPnl1069aT4OCZDB06gttu\n6wbAzz//SFDQVDZs2MSFC/+xZs0KVq16jgoVAkhKSmTy5HFUq1adDh065vv3KCobN/6PQYPuN+z9\nr/r44w+46ab6jB49lu3bv+H1119hypQZGfNjYmJ4//13eO+9T0hISGDUqGF07dqdBx8cyYMPjgQg\nKGgKEyY8DsD99w9j/vxgVq5cZ9fcLlsc0tPTAXBzc6NXrz7cfXc/pk8PonnzlgYnE8J4KSkphIdf\nxt+/DFqfxM/PL6MwALRr157PP/+Eo0eP8Msvh+nVqw8VKgQA4O3tw+rVz+Pr63vdOs+cOU1IyCJS\nUlLw8fFh3rwlrF+/lp4976RDh44cOLCP7777luDgedx7b19q165DnTp12bv3BzZtegdfX1/efnsz\n7u5udOvWk+XLl5CUlIi3tw9BQU9RuXKVjPeKjY3l5MkTzJjRAIAPP3yPXbu+JyEhgXLlyrFkyUq2\nbfuaL7/8jPT0dEaPHkt0dDTvvfcWbm5utGjRivHjJ3Pp0kVWrlxGcnIS4eGXefTRCXTpcq0dzp49\nw7JlC6/7Pe+4oxf33DMo4/mvvx5l2LCHAOjQoRObNr1y3fK+vr5UqVKVhIQEEhMTsowhv2vXDvz9\n/TMGB/P398fb25vQ0D+pX79Bfv5b88Uli8OxY78SFDSFoUMf5KGHRuHn58emTW8ZHUsIAO7vUT/P\nb/nZCQz0JywspsDve+jQQSZNeozIyAhMJhP9+w+ibdtb+O67bVSrViPL8tWqVefChf+4fDmMBg0a\nXjfPz88vy/IvvLCGESNG0qFDR/bs2cWff+ocs1y6dJFXX32TsmXL4eHhyc6d39G7d1+2b/+aZ599\ngVWrQhg8eAi33tqJgwd/4sUXn+eZZxZlvP6XX36hVq3agOWLYFRUFGvWrMfNzY1p0yZx8uRxwLKh\nXbZsNdHRUUyYMIaXX96Mj48PCxfO4eefDwAmHnhgOK1bt+XYsaO88spL1xWHGjVq8vzzG3Jt17i4\nuIz2KFWqFHFxsVmWqVSpMg8+eB9paekZewtXbd68iXnzFl83rV69Bhw5ckiKQ1GJjY0hJGQJGzf+\nj/T0dJo1k70EIa66elgpKiqSqVMnUrVqNQACAwO5cOF8luXPnj1Nu3btuXw5jEuXLl43788//8Bs\nTqdhw0YZ006f/pdmzVoA0LlzVwC2bfs6Y77ZfO2QWNmy5ShbthwA/foNYOXKZdSuXYeaNWtTtmw5\nTp0KZfPm13jrrdcBcHe/flMWERFBhQoVAMvRAU9PT+bNC8bX15dLly6RmpoKkFFAzp49Q2RkBDNm\nWA7dxMfHc+7cWVq0uJnXX3+FL7/8FDBlvO5aG+S951C6dGni4+My1ntj4TxwYC/h4ZfZsuUzAKZP\nn0zz5i1p0qQZf/99Cj8/P2rUqHndawICKnL5chj25BLFwWw2s3XrFwQHB3H+/Dnq1KlLSMhqunfv\naXQ0IUqcsmXLMWfOQh5/fByNGr1N8+YtCQ8PZ8+e3XTu3AWAAwf2cfbsWVq1ak21atWZPXsGPXrc\nSfny5YmPj2fFiiWMGjXmuvXWrl2XkyeP065de7799iuio6Pw8vIiPPwyAH/88XvGspkPrdSsWQsw\n8/bbmxk4cDAAtWrVYejQETRv3pJ///2HI0cOXfdeAQEBxMRY9qJCQ/9k9+6dbNz4OomJiYwePSJj\nOZPJ8j5Vq1anUqXKrFmzHg8PD7Zu/ZwGDRry8ssv0q/fAG69tRNffvkZX331xXXvY8ueQ/PmLdm/\nfy9NmjTjwIG9tGx583Xz/f3L4O3tjZeXFyaTCT8/P2JjLXsXBw/+lO15m5iYaMqVK59lelFyieLw\nww+7GDVqOJ6enkybFsQTT0zPcjxUCHFN3bo3MXjwENasWcGiRSEsX/4sa9euYvPm1wDLYZAVK9bg\n7u5O1arVmDDhcYKDZ+Lm5kZ8fLx1g9r5unVOnPgEK1Ys4fXXX8HHx4e5cxdy/vw5li5dwLfffm0t\nAtnr0+ceXnnlRVq3bpuxrlWrlpGcnExSUiJPPDHjuuVbtmzJ0qUhgGUD7uvry/jxjwDZf+suX748\nQ4YMZ9Kkx0hLS6Nq1Wr06HEH3bv35IUX1vLmm5sIDKxEZGRkvtty4MDBLFr0DOPHj8bT0zPj8Ne7\n775JjRo16dy5KwcP/sRjj43MON/Rrl17wLK3dfVxZidOHGfs2In5zpIfpsy7ciWc+dS/4Tyxbg9t\nVCATBzbPdeGUlBSSk5MpXbo0ZrOZhQufYejQEVmOjTqiwh5bdibSFtdIW1wTGOhPUNBs7rln0HWH\ntpxBdHQUixbNY/nyZ21aPjDQv0A3aTnlTXA//niA22+/jfnznwYsN7DNnbvAKQqDEMI2Y8aM4+OP\nPzA6RpF777237b7XAE5WHCIirjBt2mT69buTkydPYDZff5JLCOE6ypevwKxZTxsdo8g9+uh46tXL\n/9Vs+eUU5xzMZjNbtrzDvHnBhIeH07hxU1asWMMtt2Q9VieEECJvTlEc/vorlCeemICPjw/PPLOI\nxx4bj6enp9GxhBDCYTlscUhISCAi4grVqlWnfv0GrFnzAp063ZbrFQ9CCCFs45DnHEKP/0iXLu15\n9NGRGd1gPPDAcCkMQghRROy256CUcgPWAy2BJGCM1jo00/x+wFwgFXhVa70xr3VeunSBw1+u5Lze\ng7u7O3ff3Y+UlBQZv1kIIYqYPfccBgA+WutbgSeBVVdnKKU8gWeBO4GuwGNKqcq5rWz1s2u5o8et\nnNd7qFG3Kdu27Wb+/MVSGIQQwg7sWRw6A18DaK0PAG0zzWsMhGqtI7TWycAeoEtuK5sdPJeklHSa\n3z6eR2a9RLNmud8EJ4QQouDseUK6DBCV6XmaUspDa52azbwYoGxuK0uKj5Kh2DIJDJTxJq6StrhG\n2uIaaYvCseeeQzSQ+X/HzVoYspvnD+S/0xIhhBB2Yc/isBe4G0Ap1QE4lmneSaCBUqqCUsoLyyGl\n/XbMIoQQIh/s1vFepquVWgAmYBTQGvDTWm/IdLWSG5arlV6wSxAhhBD55ki9sgohhCgmDnkTnBBC\nCPuS4iCEECILKQ5CCCGyKHEd79mj2w1HZUNbDAWmYGmLY8AErXW6EVntKa92yLTcBuCK1vrJYo5Y\nbGz4TLQDVmO5COQCMEJrnWhEVnuzoS2GA9OBNCzbiv8ZErQYKaXaAyFa6243TM/3drMk7jkUabcb\nDi63tvAFFgHdtdadsNxE2NeQlPaXYztcpZQaC7jCbfO5fSZMwEZglNb6ag8FtQ1JWTzy+lysBG4H\nOgHTlVLlizlfsVJKBQEvAz43TC/QdrMkFoci7XbDweXWFklAR611vPW5B+CU3xDJvR1QSnUE2gMv\nFX+0YpdbWzQEwoGpSqldQAWttS7+iMUm188F8CuWL00+WPaknP3SzL+AQdlML9B2syQWh2y73chh\nXp7dbji4HNtCa52utb4IoJSaDPgB24o/YrHIsR2UUlWBZ4BJRgQzQG5/HxWBjsDzWL4x91RK9Sjm\nfMUpt7YA+A04BBwHvtBaO3UvDFrrD4GUbGYVaLtZEouDdLtxTW5tgVLKTSm1ErgDuFdr7azfjHJr\nh/uwbBS3Yjm0MEwpNbJ44xWr3NoiHMs3xJNa6xQs36pv/DbtTHJsC6VUC6APUBeoA1RSSt1X7AlL\nhgJtN0ticZBuN67JrS3AchjFBxiQ6fCSM8qxHbTW67TWbawn4JYBb2utNxkRspjk9pk4Bfgppa6O\nPn8blm/Nziq3togCEoAErXUacAlw6nMOuSjQdrPE3SEt3W5ck1tbAAet/37g2rHUtVrrjw2Iald5\nfSYyLTcSaOQiVyvl9PfRA0uRNAH7tNZPGBbWzmxoi3HAI0AyluPxj1qPuTstpVQd4F2tdQel1DAK\nsd0sccVBCCGE8UriYSUhhBAGk+IghBAiCykOQgghspDiIIQQIgspDkIIIbIocR3vCddkvQTvD+DE\nDbP6aa3P5PCaeQBa63mFeN+RWDqqO22d5AvswtKJYWpOr8thXQuAg1rrz5RS32utu1un/6K1blXQ\njNZ17ARqALHWSWWw3Ncw/Oqd8jm87jEgRmv9TmHeX7geKQ6iJDlf2I1oAX2mtR4JoJRyB3YCE4G1\n+VmJ1npupqfdMk0vqt9pjNZ6J2Rc4/8BMA2YlctrOmL5fYTIFykOosRTSjUDnsNy818lYJXWel2m\n+Z7Aq0Az66T1WuuN1p4nXwJqAunAbK319tzeS2udppTah6UTO5RSo7B0+2zG0k/PJCydHmb3fpuw\nbIhbW1/7o9a6vVLKDHhi2Tu5WWt9USlVAUvfP7WBnsAC6zJ/Y7lZKzyPZimNpduQH63vdZ81p6/1\n3xjAC+gP9FBK/Qf8kt/2EK5LzjmIkqSaUuqXTP9mWqePARZprdsB3YHFN7yuI5YeSG/mWhfNYPnm\n/6rWug2WjeRLSil/cqGUCgB6A3uVUs2BYKCr1ro5EIelk7+c3g8ArfXj1p/tM01LBd7H0hcUwL3A\nJ0A5LHc032Vd3zdASA7xXlZKHbVu6A9g6WjxWetexDigr9a6pXV9M60b/s+AuVrrbwrSHsJ1yZ6D\nKElyOqw0HeillJqNpasEvxvm/wYopdQ3WDrgu3qY5XagkfVcAFi+mdfD8g06s/5KqV+wdMHgBnwE\nvIPl0NLnmb7FbwBew7Lxze798rIZWIOl19ShwNNYuhqvBXyvlAJwB67k8PoxWuud1i7KPwS2Xu0O\nQik1EOinLCvphmWAmxvZ2h5CSHEQDmELEAF8DrwLPJB5ptY6XCnVFEvvtHcDh63P3YEeWusrAEqp\nakB2J28zzjlkZv1GnpkJ8Mjl/XKltT5o7fysHVBDa71PKXUPsEdr3d/6nj5c34NmduvZp5RaB7yh\nlGqJpfPFn7EUn91YxjHIrgtzW9tDCDmsJBzCHVgOjXyKZSSrqyeOsT7uD7wJfAk8juWKnprADmCC\ndZkmWDaapfLxvjux7FVUsD5/FMs3/JzeL7Mbxxa46i0sx/3ftT7/EbhVKdXQ+nwOsMKGbKuxnHcY\nh+X8SDqwBMvv3BtLIQDLsJBXcxS2PYQLkeIgHME8YI9S6jBwF/APln76r/oKS/fMx4GfgI+01seA\nyUAHpdSvwHvAg1rrGFvfVGv9K7AU2KWU+h3L+YGnc3m/zD4Fjlr3BDJ7E2hl/YnW+gKWnkO3KKWO\nYTmZPd2GbElYzoc8g6XH0V+A34HDWIrV1eFBtwNPKaUGU8j2EK5FemUVQgiRhew5CCGEyEKKgxBC\niCykOAghhMhCioMQQogspDgIIYTIQoqDEEKILKQ4CCGEyOL/TU1XzOxEVQ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1124681d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyUEIIUQWkhyEEEJkIclBCCFEFv8PhC4w5lDBalgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112443eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Running our best classifiers with tuned parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "Model with rank: 1 Mean validation score: 0.829 (std: 0.027) Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.82329262777  -  0.821754862053\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 500, max_depth = 100)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RandomForest\"]=clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost\n",
    "Model with rank: 1 Mean validation score: 0.808 (std: 0.041) Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.27%\n",
      "XG Boost:\n",
      "Accuracy          F-score\n",
      "0.81433740389  -  0.81433740389\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.set_params(learning_rate = 0.1, max_depth = 6)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"XG Boost:\")\n",
    "print(\"Accuracy\"+\"          \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting\n",
    "Model with rank: 1 Mean validation score: 0.830 (std: 0.011) Parameters: {'max_depth': 14, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.800814111262  -  0.799434644957\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 100,learning_rate = 0.25,max_depth=14,max_features=7)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GradientBoostingClassifier\"]=clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hyperparamter tuning and running our algorithms with the tuned hyperparameters our results are almost identical.\n",
    "However, random forest remains our best classifier with a precesion of 83.11%\n",
    "Gradient Boosting Classifier is also close to the best with a precision of 82.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we would select to deploy Random Forest to predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
