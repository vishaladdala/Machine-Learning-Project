{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sys,os\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Isham, Miss. Ann Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17595</td>\n",
       "      <td>28.7125</td>\n",
       "      <td>C49</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>661</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frauenthal, Dr. Henry William</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17611</td>\n",
       "      <td>133.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Carlsson, Mr. August Sigfrid</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350042</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Simmons, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392082</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Adahl, Mr. Mauritz Nils Martin</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C 7076</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lefebre, Master. Henry Forbes</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4133</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hanna, Mr. Mansour</td>\n",
       "      <td>male</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2693</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Denkoff, Mr. Mitto</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349225</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n",
       "      <td>female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dimic, Mr. Jovan</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315088</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mamee, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sjostedt, Mr. Ernst Adolf</td>\n",
       "      <td>male</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>237442</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Coleridge, Mr. Reginald Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W./C. 14263</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370373</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "177          178         0       1                Isham, Miss. Ann Elizabeth   \n",
       "660          661         1       1             Frauenthal, Dr. Henry William   \n",
       "756          757         0       3              Carlsson, Mr. August Sigfrid   \n",
       "563          564         0       3                         Simmons, Mr. John   \n",
       "365          366         0       3            Adahl, Mr. Mauritz Nils Martin   \n",
       "176          177         0       3             Lefebre, Master. Henry Forbes   \n",
       "296          297         0       3                        Hanna, Mr. Mansour   \n",
       "335          336         0       3                        Denkoff, Mr. Mitto   \n",
       "258          259         1       1                          Ward, Miss. Anna   \n",
       "43            44         1       2  Laroche, Miss. Simonne Marie Anne Andree   \n",
       "349          350         0       3                          Dimic, Mr. Jovan   \n",
       "36            37         1       3                          Mamee, Mr. Hanna   \n",
       "232          233         0       2                 Sjostedt, Mr. Ernst Adolf   \n",
       "242          243         0       2           Coleridge, Mr. Reginald Charles   \n",
       "289          290         1       3                      Connolly, Miss. Kate   \n",
       "\n",
       "        Sex   Age  SibSp  Parch           Ticket      Fare Cabin Embarked  \n",
       "177  female  50.0      0      0         PC 17595   28.7125   C49        C  \n",
       "660    male  50.0      2      0         PC 17611  133.6500   NaN        S  \n",
       "756    male  28.0      0      0           350042    7.7958   NaN        S  \n",
       "563    male   NaN      0      0  SOTON/OQ 392082    8.0500   NaN        S  \n",
       "365    male  30.0      0      0           C 7076    7.2500   NaN        S  \n",
       "176    male   NaN      3      1             4133   25.4667   NaN        S  \n",
       "296    male  23.5      0      0             2693    7.2292   NaN        C  \n",
       "335    male   NaN      0      0           349225    7.8958   NaN        S  \n",
       "258  female  35.0      0      0         PC 17755  512.3292   NaN        C  \n",
       "43   female   3.0      1      2    SC/Paris 2123   41.5792   NaN        C  \n",
       "349    male  42.0      0      0           315088    8.6625   NaN        S  \n",
       "36     male   NaN      0      0             2677    7.2292   NaN        C  \n",
       "232    male  59.0      0      0           237442   13.5000   NaN        S  \n",
       "242    male  29.0      0      0      W./C. 14263   10.5000   NaN        S  \n",
       "289  female  22.0      0      0           370373    7.7500   NaN        Q  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in training data\n",
    "training_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/train.csv\")\n",
    "training_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data statistics using .describe()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Transformations\n",
    "#method to convert ages to bins called 'Unknown'for [-1,0], 'Baby' for [0-5],\n",
    "#'Child' for [6-12], 'Teenager' for [13-19], 'Student' for [20-25], 'Young Adult' for [26-35], 'Adult' for [36-60],\n",
    "#'Senior' for [61-100]\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 19, 25, 35, 60, 100)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method which simplifies the cabin feature by filling N/A values with 'N'\n",
    "#also it takes only the first letter the cabin using splicing\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert fares into bins using the numbers from .descrobe() statistics earlier\n",
    "#the N/A values are filled with -0.5\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Extraction \n",
    "#the below method is used to extract two features from the Name column\n",
    "#method to format the Name column to extract LName and NamePrefix\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to drop the features which we inconsider inconsequential\n",
    "#we have selected ticket,Name,Embarked columns to be dropped due lack of variance or too many N/A values\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method calls all the above transformation methods one by one and applies it on our dataframe\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to proceed to apply the transformations on the training data\n",
    "transformed_train = transform_features(training_data)\n",
    "transformed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as we can see above our training data now has :\n",
    "#1. LName, NamePrefix instead of 'Name' which has been dropped\n",
    "#2. 'Ticket', 'Name', 'Embarked' have been dropped \n",
    "#3. 'Fare', 'Age' have been converted into convenient bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1014</td>\n",
       "      <td>1</td>\n",
       "      <td>Schabert, Mrs. Paul (Emma Mock)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13236</td>\n",
       "      <td>57.7500</td>\n",
       "      <td>C28</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1007</td>\n",
       "      <td>3</td>\n",
       "      <td>Chronopoulos, Mr. Demetrios</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2680</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>3</td>\n",
       "      <td>Samaan, Mr. Elias</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2662</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>Chaffee, Mrs. Herbert Fuller (Carrie Constance...</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>W.E.P. 5734</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>E31</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1090</td>\n",
       "      <td>2</td>\n",
       "      <td>Baimbrigge, Mr. Charles Robert</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 31030</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "122         1014       1                    Schabert, Mrs. Paul (Emma Mock)   \n",
       "115         1007       3                        Chronopoulos, Mr. Demetrios   \n",
       "29           921       3                                  Samaan, Mr. Elias   \n",
       "14           906       1  Chaffee, Mrs. Herbert Fuller (Carrie Constance...   \n",
       "198         1090       2                     Baimbrigge, Mr. Charles Robert   \n",
       "\n",
       "        Sex   Age  SibSp  Parch       Ticket     Fare Cabin Embarked  \n",
       "122  female  35.0      1      0        13236  57.7500   C28        C  \n",
       "115    male  18.0      1      0         2680  14.4542   NaN        C  \n",
       "29     male   NaN      2      0         2662  21.6792   NaN        C  \n",
       "14   female  47.0      1      0  W.E.P. 5734  61.1750   E31        S  \n",
       "198    male  23.0      0      0   C.A. 31030  10.5000   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to apply the above feature transformations on the test data\n",
    "test_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/test.csv\")\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Kelly,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Wilkes,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Myles,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Wirz,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Hirvonen,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex          Age  SibSp  Parch        Fare Cabin  \\\n",
       "0          892       3    male  Young Adult      0      0  1_quartile     N   \n",
       "1          893       3  female        Adult      1      0  1_quartile     N   \n",
       "2          894       2    male       Senior      0      0  2_quartile     N   \n",
       "3          895       3    male  Young Adult      0      0  2_quartile     N   \n",
       "4          896       3  female      Student      1      1  2_quartile     N   \n",
       "\n",
       "       Lname NamePrefix  \n",
       "0     Kelly,        Mr.  \n",
       "1    Wilkes,       Mrs.  \n",
       "2     Myles,        Mr.  \n",
       "3      Wirz,        Mr.  \n",
       "4  Hirvonen,       Mrs.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test = transform_features(test_data)\n",
    "transformed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now as a next step, we need to remember that machine learning algorithms need all the input to be numerical values\n",
    "#But as we can observe from above 'Sex', 'Age' , 'Fare', 'Cabin', 'Lname', 'NamePrefix' are in nominal(string) format\n",
    "#Hence we need to convert these into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we proceed to use LabelEncoder from sklearn preprocessing to achieve \n",
    "#Every column in numerical form\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_test = encode_features(transformed_train, transformed_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>401</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>843</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>552</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>851</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>342</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  NamePrefix\n",
       "0          892       3    1    7      0      0     0      7    401          19\n",
       "1          893       3    0    0      1      0     0      7    843          20\n",
       "2          894       2    1    3      0      0     1      7    552          19\n",
       "3          895       3    1    7      0      0     1      7    851          19\n",
       "4          896       3    0    4      1      1     1      7    342          20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we proceed to test the various classifiers in Scikit-Learn to \n",
    "#see which classifiers works best on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "#Below we are splitting up our training data into 80% training , 20% testing data \n",
    "# X contains all the columns except 'Survived' because that is the feature we predict\n",
    "# Y consists only of the column 'Survived'\n",
    "X = data_train.drop(['Survived'], axis=1)\n",
    "Y = data_train.Survived\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 15]\n",
      " [24 44]]\n",
      "0.782122905028\n"
     ]
    }
   ],
   "source": [
    "#Our first classifier will be Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.588385311871  -  0.553568075117\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "classifiers = {}\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.553503800581  -  0.513629555108\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.618025933378  -  0.618025933378\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SVM\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.533551307847  -  0.533551307847\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.681056338028  -  0.681056338028\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LR\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.563109769729  -  0.563109769729\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.822671026157  -  0.818504918399\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.800313547954  -  0.800313547954\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"ADA\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.796362620165  -  0.800587413369\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 30,learning_rate = 1)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GB\"]=clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.532415045831  -  0.532415045831\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"PT\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "NN\n",
      " :  0.547973395931    0.499699865862\n",
      "DNN\n",
      " :  0.549087301587    0.605349318131\n",
      "SVM\n",
      " :  0.618025933378    0.618025933378\n",
      "NB\n",
      " :  0.533551307847    0.533551307847\n",
      "LR\n",
      " :  0.681056338028    0.681056338028\n",
      "KNN\n",
      " :  0.563109769729    0.563109769729\n",
      "RF\n",
      " :  0.832570981444    0.82411971831\n",
      "ADA\n",
      " :  0.800313547954    0.800313547954\n",
      "GB\n",
      " :  0.794973731277    0.803404873687\n",
      "PT\n",
      " :  0.532415045831    0.532415045831\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hence we see that Random forest classifier gave the best performance with an accuracy ~83% and an F-score ~83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next we proceed to apply \"Feature Scaling\" to see if the performance of our various classifiers improves\n",
    "#Feature scaling aims to bring the values of our numerical features between 0 and 1\n",
    "#This is mainly done because large numerical values may skew our data and make the classifier weight it more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = data_train.drop(['Survived'], axis=1)\n",
    "YY = data_train.Survived\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "XX[XX.columns] = scaler.fit_transform(XX[XX.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.209919</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.379469</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.115340   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.209919   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.379469   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.307958   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.017301   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.575758  \n",
       "1    0.606061  \n",
       "2    0.484848  \n",
       "3    0.606061  \n",
       "4    0.575758  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 15]\n",
      " [23 45]]\n",
      "0.787709497207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.794658506595  -  0.79452045607\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "classifiers = {}\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.794698189135  -  0.81146154706\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.79598759222  -  0.79598759222\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SVM\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.734225911022  -  0.734225911022\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.79590878605  -  0.79590878605\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LR\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.781843281914  -  0.781843281914\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.829733959311  -  0.81719539459\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.800313547954  -  0.800313547954\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"ADA\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.800627654818  -  0.792156829868\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 30,learning_rate = 1)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.72692432372  -  0.72692432372\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"PT\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "NN\n",
      " :  0.794678627319    0.791682316119\n",
      "DNN\n",
      " :  0.79459926224    0.783350100604\n",
      "SVM\n",
      " :  0.79598759222    0.79598759222\n",
      "NB\n",
      " :  0.734225911022    0.734225911022\n",
      "LR\n",
      " :  0.79590878605    0.79590878605\n",
      "KNN\n",
      " :  0.781843281914    0.781843281914\n",
      "RF\n",
      " :  0.828326067516    0.818525598033\n",
      "ADA\n",
      " :  0.800313547954    0.800313547954\n",
      "GB\n",
      " :  0.792176391683    0.792176391683\n",
      "PT\n",
      " :  0.72692432372    0.72692432372\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers after feature scaling\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we see the performance of various classifiers has improved dramatically after feature \n",
    "#But we see that Random Forest still is our best performing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trying the concept of hyperparameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.322 (+/-0.005) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.103) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.698 (+/-0.084) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.103) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.703 (+/-0.092) for {'C': 1, 'kernel': 'linear'}\n",
      "0.681 (+/-0.088) for {'C': 10, 'kernel': 'linear'}\n",
      "0.681 (+/-0.088) for {'C': 100, 'kernel': 'linear'}\n",
      "0.681 (+/-0.088) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.85       406\n",
      "          1       0.78      0.71      0.74       263\n",
      "\n",
      "avg / total       0.81      0.81      0.81       669\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.697 (+/-0.082) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.678 (+/-0.060) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.697 (+/-0.082) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.685 (+/-0.072) for {'C': 1, 'kernel': 'linear'}\n",
      "0.668 (+/-0.066) for {'C': 10, 'kernel': 'linear'}\n",
      "0.668 (+/-0.066) for {'C': 100, 'kernel': 'linear'}\n",
      "0.668 (+/-0.066) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.85       406\n",
      "          1       0.78      0.71      0.74       263\n",
      "\n",
      "avg / total       0.81      0.81      0.81       669\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "\n",
    "#clf = svm.SVC()\n",
    "#clf.set_params(C = 100, kernel = \"rbf\")\n",
    "#svm_clf = clf.fit(X_train,Y_train)\n",
    "#svm_predict = svm_clf.predict(X_test)\n",
    "#svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "#accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "#f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "#print(\"Support Vector Machines:\")\n",
    "#print (accuracy.mean(), \" - \",f_score.mean())\n",
    "#classifiers[\"SVM\"]=clf\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.75, random_state = 5)\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train,Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.728722002635  -  0.728722002635\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\", gamma= 0.001)\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2.40 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.730 (std: 0.048)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.721 (std: 0.031)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 8, 'min_samples_leaf': 8, 'min_samples_split': 8}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.703 (std: 0.041)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 4, 'min_samples_split': 7}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.703 (std: 0.030)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 6}\n",
      "\n",
      "GridSearchCV took 36.47 seconds for 324 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.739 (std: 0.035)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.734 (std: 0.038)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.019)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.024)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.030)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.072)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.051)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3,10, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.687794089968  -  0.701646903821\n"
     ]
    }
   ],
   "source": [
    "#Model with rank: 1\n",
    "#Mean validation score: 0.734 (std: 0.028)\n",
    "#Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 6}\n",
    "\n",
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'entropy')\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.692358366271  -  0.710540184453\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.209919</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.379469</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.115340   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.209919   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.379469   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.307958   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.017301   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.575758  \n",
       "1    0.606061  \n",
       "2    0.484848  \n",
       "3    0.606061  \n",
       "4    0.575758  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.819991616365  -  0.831241895819\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.829832886206  -  0.832591102169\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'entropy')\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4FFX3wPHvpiekh5DQO5cOUgQBEbChFMEOYkFQEEEB\nIYgIIr0q6isq9p+++tp7xQIICAIiUuJFek0I6b3t/P7YJQQCYQPZTHZzPs/Dw+7M7OzJJcyZe+/M\nGYthGAghhBDFeZgdgBBCiMpHkoMQQogSJDkIIYQoQZKDEEKIEiQ5CCGEKEGSgxBCiBK8zA5AiPKi\nlDKAHUAhYAABQBrwkNZ6s32basDTwAAgz77dV8AcrXV2sX3dC4wG/AEfYC0Qo7VOOc93l2l7ISo7\n6TkId9Nba91ea32Z1loBHwAvACilvICfsP3eX6a1bgN0BQKBH+zrUUo9AYwEBmmt2wPtgHxsSaSE\nsm4vhCuwyE1wwl3Yew6RWuuT9vdewDNAY611P6XUEGC81rrLWZ+zAFuBucC3QDy25PFvsW0CgMHA\nR1rrvGLLq11oe+AJoLrWeqx93cxT75VSq4AkoDnwCjAdqKW1zlNKeQIHgeuAo8BzQBvAG/gZmKy1\nLrjkhhPiHKTnINzNr0qpbUqpY8Bu+7Lh9r+7AWvO/oDW2sB2sO2B7SCdVfxAb98mS2v93+KJwa6s\n259Lsta6pdb6OWAnMNC+/DrggNZ6F/AssEVr3RG4DKgOTHRg30JcFEkOwt301lq3A/phm3NYr7U+\nUWy993k+54tt/sFK2f5flHX7c/mt2OtXgfvsr4cDr9lf9wdGKaX+ArYAl2PrRQjhFJIchFvSWm8F\nJgCvKaUa2BevA3oqpc74vbe/7wmsB3YB3kqpJmdt46eU+lYpVeusr3JkewOwFFvtc9Y+Moq9/hjo\nopRqAVwFfGhf7gncZp9PaQ90AcaW2ghCXAJJDsJtaa3fB34HltkXfQxkAsuUUv4A9r9fwHaA/kxr\nnQssBN5QSkXZt/HFNqxTTWt97KzvcGT7BKCjUspin6O4rpSYc4D/AW8Bn2its+yrfgAm2PfhC3yJ\nJAfhRJIchLsbC9yglLrePnl7HbZEsEUptQP40/7+Wq11PoDWeh7wCbYrmP4CtmE787/pXF/gwPb/\nxZYg/sU24f37BWJ+Fduw0WvFlj0CVAO2A3/b/17kYBsIUWZytZIQQogSpOcghBCiBEkOQgghSpDk\nIIQQogRJDkIIIUpwmcJ7BQWFRnJy1oU3rALCwgKQtrCRtjhN2uI0aYvTIiODLBfeqiSX6Tl4eXma\nHUKlIW1xmrTFadIWp0lbXDqXSQ5CCCEqjiQHIYQQJUhyEEIIUYIkByGEECVIchBCCFGCJAchhBAl\nODU5KKW62B+DePbyAUqpTUqp35VSDzgzBiGEEGXntOSglIrBVnLY76zl3thq3V+H7WEmD56qgy+E\nEKJ8FBRaSUzNvujPO/MO6b3AzcA7Zy1vAezRWicDKKXWYnsK10dOjEUIIdyCYRhk5xaQnJ5LckYu\nyem5pKTnkpyRZ/s7PZek9Gx2bvyOwzt/Julo7EV9j9OSg9b6k2KPZywuGEgt9j4dCHFkn5GRQeUQ\nmXuQtjhN2uI0aYvTXLEtCgqtJKflkpiWTWJqDomp2SSl5thf294npuWQm1d43n1kpxxmx08vEX9o\nF75+ARcdixm1ldKA4v9qQUCKIx9MSEh3SkCuJjIySNrCTtriNGmL0ypbW9jO9gtJzsgtOrs/1+u0\nzDxKe/xacIA3UWH+hAX6EhbkS2iQ75mvg3wZfs9txB/axYABg5gzZ8FFx2xGcogFmiqlwrE9nrEn\nsMSEOIQQ4pIVWq2kZuSVcuC3Dffk5p//bN/by4OwQF+a1g0lzH7AP3Wwt732ITTQFy/Pc08Tx8bu\nok6jlgDMn7+Y/fv3cc0111/Sz1VhyUEpNRQI1FqvUEpNxPbAdA/gDa310YqKQwghHFV8bP98Z/xp\nmXmU9rTlIPvZ/pkH+zNfV/PzwmIpe/HUY8eO8sQTMXz33dd8++1PdOzYmcaNm9K4cdNL+KltnJoc\ntNYHgK721+8VW/4V8JUzv1sIIc7HajVIzcyzHeDTc0mxT+ye8Tojt9SxfS9PD8KCfGhaO+S8B/6Q\nQF+8vcr/otCCggJee+1lFi6cR2ZmBl27diM42KGpW4e5zPMchBDCEdm5BRyOT2ffoaTzHvhTL3C2\nH+jvTY1Qf9tYvn1M/+zXF3u2f6m2bNnEpEnj2blzO+Hh4cybt5w777yr3GOR5CCEcAmnzvbPeZZf\n7HVOqWf7FkIDfWlSO+S8B/5QJ53tl5fPP/+UnTu3M2TIMGbMmE1ERIRTvkeSgxDCdDl5BcWu1z91\n7X7e6dcZuaRm5GEt5XQ/0N+b6iG2s/2akYH4eVlKHPgD/b1NOdu/FIZh8PPPP9Knz7V4eHgwZco0\n+vUbQNeu3Zz6vZIchBBOY7UapGXlnePAn3vGgT8798Jn+41qB5++bLP4GX+QL2GBPngXe/pbZbuU\n9WLt27eHmJjHWLPmV5YufZ67776PwMBApycGkOQghLhIuXmF5z7YF3t9obP9an5eRAT7lbxev9jr\nQH9vPFzsbP9S5ebm8vzzz/D888+Qm5vL1Vdfy5VXXlWhMUhyEEKcwWoYpGfmlXLgt/UEsnMLzrsP\nTw/72X6t4LMO9j5nnP37eMuzns+2fv1aHnvsEfbu3UN0dE3mzl1I//43VfhwmCQHIaqQ3PzCUu/Q\nTbaP7RdaSz/bDw/2JSzw7AP/6deBAVXvbL+8HD58iP379/Hggw8xZco0goKCTYlDkoMQbsJqNTiZ\nkk1cUhYJqTlnnPWfSgJZFzzb96FBzaAS1+ufOviHBvriK2f75cpqtfK///2Xfv0GEBISyu23D6F9\n+w4o1dzUuCQ5COFisnIKiEvKIi4p0/Z3YhZxSVmcSM4mr8B6zs8E+HoRFuRLw1rB5z3wB8nZfoXb\nsWM7kyePZ8uWTcTG7mT27AVYLBbTEwNIchCiUiq0WjmZksPxYgf/U3/SMvNKbO/r40nd6CCqB/sR\nHR5QdAPXqbF9Xx85269MMjIyWLx4PitWLKewsJBBg27m4YcfNTusM0hyEMJE6Vl5Z5z9n/pzIjm7\nxLi/BYgI8aN1o3CiwwOoGR5AdHgA0RHVCA30oUaNYLe4fNPdrVv3G2PHjuLo0SPUr9+AhQuX0qfP\ntWaHVYIkByGcLL/AyomUbHsCyDydBBKzyMwpOQcQ4OtF/egg24G/KAEEEBXmf8a1/MI1BQUFkZSU\nyMSJk3n00Un4+/ubHdI5SXIQohwYhq20w9k9gLjELBJSs0vU8fH0sFA91J+mdUKLDv6nEkFQgOvd\nxSvOLz8/nxUrXqJPn2to0aIlbdu2588/dzmt7EV5keQgRBnk5hcSn1QyAcQnZ53zLt+gAG+a1A4p\nkQAiQ/3PW5tfuI8//tjI5MnjiY3dycaNv/N///c+QKVPDCDJQYgSrIZBclruGQf/U8NBiWm5Jbb3\n8rQQFRZAdP0zE0B0RADV/LxN+AmE2ZKTk5gz52neeedNAIYNu5cnn5xpblBlJMlBVFnZuQVnJQDb\nn/ikrHNeEhoa6EPzeqFER1Q7IwFUD/bDw0OGgYTNH39s5L77hnDy5ElatGjJokXL6NKlq9lhlZkk\nB+H2ktJyOJKQcUYCOJ6URWpGyUtCfbw9SgwB2SaDA/D3lf8u4sKaNGmCn58/06fPYvToh/H2ds3e\no/y2C7eUkZ3Ppth41u+IY++xtDPWWYDwYD9aNQw/IwHUDA8gNMhXbgQTZZKTk8Nzzy2lZcvWDBhw\nE+HhEWzYsBUfHx+zQ7skkhyE2ygotPL33kTW74hj256TFFoNLBZo1TCcZnVCioaDosL8peCbKBer\nVv3ClCkT2b9/Hx06dKR//4FYLBaXTwwgyUG4OMMw2Hs0lfU74/hjV3zRfQN1IgPp1jqarq2iCA30\nNTlK4W7i4+N56qmpfPrpx3h6ejJ69FhiYqa61SXIkhyESzqZks3vO+PYGHuCYyczAQip5sP1l9fl\nilbR1IsKMjlC4a5iY3cxYMD1pKWl0qFDRxYvfo42bdqaHVa5k+QgXEZWTgGb9QnW74hj9+EUAHy8\nPenaMoorWkfTskEYnh5y74BwrmbNFO3aXUb//gO5557heHq65xClJAdRqRUUWtm5P4nfd8ax9d+T\n5NsvMW1eL5QrWkfTt3sjMtNzTI5SuLOMjHQWLpxLtWqBPP74k3h6evLxx1+41RDSuUhyEJWOYRgc\nis9g/Y44Nu6KIy0rH4CaEQG2eYSW0USE+AEQ4OctyUE4hWEYfPPNV0ybFsPx48dQqjkTJ8bg4+Pj\n9okBJDmISiQpLYcNu+L5fUccR+3zCIH+3lzdsQ7dWkfTIDqoSvynFOY7dOggU6dOYuXKH/Dx8WHS\npMd55JGJbnEVkqMkOQhT5eQVsEUnsH5HHP8cTMbAVo6ik4rkitbRtGkUITWIRIWKj4+jZ88uZGVl\nceWVV7Fw4TM0adLU7LAqnCQHUeGsVoPYg8ms33GcLbsTyMu3zSM0qRNCt9bRdG5eQ2oSiQpXUFCA\nl5cXUVHR3HffSFq1as2tt95RZXurkhxEhTmSYJtH2LAzjhR76YrIUD+6ta7JFa2iqBEWYHKEoipK\nSkpk9uynOHEinnff/RCLxcLMmXPMDst0khyEU6Vm5LJxl62MxaETGYDtYTa92tfiitbRNKkdUmXP\nzIS5DMPggw/e4+mnnyQxMZGWLVuTkpJMWFi42aFVCpIcRLnLyy9k678nWb8jjp37k7AaBp4eFto3\nqU631tG0axIhTzQTptq9WxMTM4H169cSEBDAzJlzefDBh/DykkPiKdISolwUFFrZfTiFDbvi2aJP\nFD34pmHNILq1rknnFjUIDqg6V3qIyisrK4uBA68nKSmJvn37MW/eIurUqWt2WJWOJAdx0ZLTc9m+\nL5G/9yay80ASuXm2hBAe7EufDrbLT2tGVDM5SiFsUlKSCQ0NK+ophISEcsMN/cwOq9KS5CAcVmi1\nsvdoGn/vtSWEIwkZReuiwvxp0zaCDk0jaVYvVMpei0ojLu4406dPZdu2raxevQF/f3/uvPMus8Oq\n9JyWHJRSHsByoB2QC4zUWu8ptv4u4DGgEHhDa/2Ss2IRFy81M48dp3oH+5PIyrVVPfXy9KB1w3Da\nNI6gbaMIosLlSiNRuRQWFvLmm68yb95sMjLS6dTpcpKSEqldu47ZobkEZ/YcBgF+WusrlFJdgaXA\nTcXWLwFaARnALqXU/7TWyU6MRzjAajXYf9zWO9i+L5EDcelF6yKC/ejSKoq2jSJoXi8MXx+ZVBaV\n05YtWxgx4gG2bdtKSEgoS5Y8x7Bh9+IhhRkd5szk0AP4HkBrvUEp1ems9X8DIUABtodzGU6MRZQi\nIzvf1jvYl8iOfUlkZNtqGXl6WGhRP4w2jSJo2ziCmhEBctmpqPSsViv33nsvO3fu5Lbb7mTmzLlE\nRkaaHZbLcWZyCAZSi70vVEp5aa0L7O93AFuATOBTrXXKhXYYGSk1+k+5lLawWg32HUtlS2w8m2Pj\n2X0oGas9NUeE+NG9XS06No+iXdPqBLjAncrye3FaVW0LwzDYs2cPTZvaylysWLGCnJwc+vTpY3Jk\nrsuZySENKP6b6nEqMSil2gL9gIbYhpXeVUrdprX+qLQdJiSkl7a6yoiMDCpzW2Tl5LPzQDJ/7z3J\n9n1JpGXa7lD2sFhoUjvENnfQuDp1IqsV9Q4y03MqfcXTi2kLd1VV2+LAgf1MnTqJ9evX8ttvf1Cv\nXn26detGQkJ6lWyPs13sCYMzk8M6YADwoX3OYXuxdalANpCttS5USp0AwpwYS5VjGAZHEzL52z6Z\nvOdIKlbD1j0IruZD9za2onatGoZLHSPhkvLy8li+/HmeeWYROTk59OzZ2+yQ3Iozk8NnwLVKqfXY\n5hSGK6WGAoFa6xVKqVeAtUqpPGAv8JYTY6kSsnMLiD2YXDSZnJyeC9gav1GtYHvvIIJ6UUFyqalw\nab//vo7Jk8eze7cmMrIGy5a9yODBt8qcWDlyWnLQWluB0Wct/qfY+peBl531/VWBYRjEJWUV3Xew\n+3AKhfbJg2p+XnRtGUWbxhG0bhhOkNydLNzIihUv8e+/uxk+fCRPPDGDkJBQs0NyOxbDcJmLhAwZ\nP4Tc/ELiUnP57c/D/L03kZOpp+cE6kcH0dZ+ZVHDmsF4eLj/WVRVHWc/F3duC6vVyvr1a+nRoycA\nx44d5fjxY3Ts2Pmc27tzW5RVZGTQRR0I5A5pF3Ai2d472JeIPpRS9Bxlf18vOjWvQdtGEbRpFE5I\noK/JkQpR/v75J5aYmAls2LCeDz/8nF69+lCrVm1q1aptdmhuTZJDJZRfYCtidyohxCdlFa2rExlI\n1zY1aVIziEa1guUpacJtZWVl8cwzi1i+/HkKCgro128gzZops8OqMiQ5VCJ/7z3Jqq3HiD2YTG6+\nrYidr48nlzWtTtvGEbRpFEF4sJ90mYXb+/nnH5ky5TEOHTpI3br1mD9/Mdddd4PZYVUpkhwqgYJC\nKx+v2suPmw4DUDMioCgZNK0TireX9A5E1bJ1658cO3aUceMmMHFiDNWqSXXfiibJwWRJaTm8/MVO\n9hxNpWZEAKMGtqJeVNW8y1VUXQUFBXz00f+49dY78Pb2Zty4CfTvfxPNm7cwO7QqS5KDiXbsT2TF\nl7vIyM6nS8so7u2r8PORfxJRtfz552YmT57A9u3bSE1NYfTosfj6+kpiMJkciUxgtRp8uW4/X607\ngKenhbuva0avy2rLDTyiSklLS2XevFm8+eZrGIbBHXcM5dZb7zQ7LGHnUHJQSlUDGmMrgRGgtc50\nalRuLC0zj1e+3EnswWSqh/jx0KDWNKwZbHZYQlSoH374jscee4QTJ+Jp2rQZixY9S/fuV5odlijm\ngslBKXU18ArgCXQD/lZK3aW1/tHZwbmb3YdTeOmLHaRm5NG+SXVG9G8hdY1ElWQYBmlpqUydOp2H\nH34UHx+5g7+ycaTnMA/bsxm+01ofV0pdBbwPSHJwkGEYfL/xEJ+s3gfAbb0b0/fyejKMJKqM3Nxc\nXn75PwwZcjc1atSgb98b2bTpb6Kios0OTZyHI9dIemit40690VrvcmI8biczJ58XPtnOR6v2ElTN\nm5ihl3FDl/qSGESVsXbtGnr37sbcuU+zdOmCouWSGCo3R3oOR5RS/QFDKRUKPAwccm5Y7uFAXBrL\nP9vBydQcWtQPY9TAVgRXk+6zqBoSEhKYOXMaH330PywWCyNGPMjUqdPNDks4yJHkMAp4DqiLrbT2\nL8ADzgzK1RmGwaqtR3n/538pLDQY0K0BN/VoWCUK4QkB8NNPPzBmzAOkpKTQtm17lixZRvv2HcwO\nS5SBI8mhndZ6SPEFSqmbgU+dE5Jry8kr4O3vNRt3xRPo782DA1rSulGE2WEJUaEaNmyEp6cnc+cu\n5P77H8TT09PskEQZnTc5KKXuAHyBWUqpGWd95gkkOZRQUGhl0XtbORCXTuPawTx0U2vCg/3MDksI\np8vMzGTJkgX06zeATp0up3Hjpvz55y78/f3NDk1cpNJ6DsHYLl0NAoo/f68AmObMoFzVtxsOciAu\nnctb1GBk/5ZSMVVUCT/88B1Tp07iyJHD7N27h//7v/cBJDG4uPMmB631q8CrSqmrtdY/V2BMLulI\nQgZfrTtAWJAv91zfXBKDcHtHjx7hiSdi+O67r/Hy8uLRRx9jwoTJZoclyokjcw65SqkvgEBsjyP2\nBOprrRs4MzBXUmi18ua3sRRaDe6+XhHgJ1VJhHtbv34tQ4feRlZWJl27dmPRomelFpKbceT09jXg\nc2yJ5EXgX+AzZwblan7cdJj9x9O5olUU7ZtUNzscIZyubdv2NG7chOeeW84XX3wnicENOXKKm621\nflMp1QBIxnYZ6xanRuVCjidm8tma/QQHeDPkmmZmhyOEU6SmpjB37tO0bdueYcPuJTAwkJ9+WiM3\nc7oxR3oOOUqpcEADXbXWBiBP3gCshsGb3/1DQaGVYdcpAv2lTpJwL4Zh8MknH9KtWyfeeut1Pvjg\nPQzDAJDE4OYcSQ7PAB8AXwH3KKV2Ij0HAH7ZcoQ9R1LppCLp1LyG2eEIUa727v2XW2+9iYceGklG\nRjpPPjmTTz75SpJCFXHBYSWt9UdKqY+11oZSqiPQDNjj/NAqt4SUbD5evZdqfl7cdZ089Fy4l127\ndnLddVeRl5fH1Vdfy4IFS6lfv4HZYYkKVNpNcJHARCAJeBbb/Q3Z2O59+B6IqogAKyPDMHjru3/I\ny7dyb9/mhEi9JOEmrFYrHh4etGjRkgEDBnHjjQPo33+g9BaqoNJ6Dv8F0oHqgI9S6lvgHSAAmFAB\nsVVaa7YdI/ZgMu2bVKdryyqbI4UbOXHiBDNnTiMoKIiFC5/BYrHw0kuvmR2WMFFpcw6Ntda3AP2B\nIcDXwLtAc631exURXGWUlJbDB7/swd/Xi7uvV3JGJVya1Wrl7bffoHv3Tnz88Qds27aVvLw8s8MS\nlUBpPYc0AK11uv1qpVu01r9XTFiV13cbD5GTV8i9fRVhQb5mhyPERduxYzuTJ49ny5ZNBAYGMX/+\nYu67b6QUyRNA6cnBKPY6XhID5OYVsn7HcUICfejepqbZ4Qhx0eLj47nhhj7k5uYyaNDNzJo1n+ho\n+Z0Wp5WWHIKUUldiG3qqZn9dNIaitV7j7OAqm42x8WTnFnJtp7pSO0m4pIyMDAIDA4mKiiImZhqt\nWrWiT59rzQ5LVEKlJYcjwCz766PFXoOtV9HHWUFVRoZh8OufR/GwWOjZrpbZ4QhRJocPH2LatBiS\nkpL48svv8fDwYNy48WaHJSqx0qqy9j7fuqpo//F0Dsanc1nT6vKMBuEy8vPzWbHiJRYvnkdWVhbd\nuvUgNTWFsLBws0MTlZyUD3XQr38eAaB3h9omRyKEYzZt2sjkyRPYtWsHERERLFz4DLffPkSusBMO\nkeTggIzsfP745wQ1Qv1p2UDOuETll52dzb33DuXkyQSGDbuXJ5+cSXi4PK5WOM5pyUEp5QEsB9oB\nucBIrfWeYus7Y6vbZAHigGFa6xxnxXMp1m0/Tn6BlV6X1cZDzrpEJWUYBkeOHKZOnbr4+/vzzDMv\nEBoaRteuV5gdmnBBF7zkRikVppR6VSn1i1IqQin1hlIqzIF9DwL8tNZXAI8DS4vt0wK8CgzXWvfA\nVo6j/sX9CM5lNQxWbT2Kl6cHPdrKpX6ictqz51+uvvpqbrjhatLSUgHo2/dGSQziojlyPearwCYg\nAls5jePY7pS+kFMHfbTWG4BOxdY1AxKBCUqp1UC41lqXIe4KE3swmfjkbDo3ryEluUWlk5OTw8KF\nc+nV6wp+/fVX2rVrT3Z2peyACxfjyLBSQ631CqXUQ1rrPGCaUmqbA58LBlKLvS9USnlprQuw1Wvq\nBozFVuH1a6XUZq31L6XtMDIyyIGvLV/rv4kF4OY+TU35/vOpTLGYraq2xcqVKxkzZgx79uyhdu3a\nvPDCCwwaNEgmnO2q6u9FeXEkORQopUKw3zGtlGoKWB34XBpQ/F/Hw54YwNZr2KO1jrXv83tsPYtS\nk0NCQroDX1t+ktNz2bgjjro1AgkP8Krw7z+fyMigShOL2apqWxiGQUzMFPbt28eoUQ8zZcoTNGxY\nq0q2xblU1d+Lc7nYJOlIcngKWAXUU0p9DlwB3O/A59YBA4APlVJdge3F1u0DApVSTeyT1FcCr5cl\n8IqwZtsxrIZB78tqy9mYMF1hYSF//fUnHTt2xmKxsGzZcgoLC2jTpp3ZoQk35EhyWAlsBroAnsAo\nrXW8A5/7DLhWKbUe2xVJw5VSQ4FA+zDVCOA9++T0eq31Nxf3IzhHodXKmm3H8PPxpGsrKcstzLV9\n+zYmTx7P339v45df1tG8eQtatmxldljCjTmSHA5hO9C/a59YdojW2gqMPmvxP8XW/wJc7uj+Ktpf\n/yaSnJ5L7w618fOR20GEOTIy0lm4cC6vvvoyVquVm2++Te5uFhXCkaNea+AWYK5SqjbwP2yJwq0f\nFbpqq/2O6Mvkjmhhjq+//pJp02I4fvwYDRs2YuHCZ+jVq0qVNBMmcuQZ0snAa8BrSqlOwCvAk458\n1lXFJ2Wx80AyTeuEUCcy0OxwRBW1cuX3JCaeZNKkx3nkkYn4+UlNL1FxLniAtz9L+jbgTiAceA8Y\n7OS4TLXqr6OA9BpExcrPz+frr79g0KBbsFgszJgxm3HjJtCkSVOzQxNVkCNn/38BHwITtNZbnByP\n6bJyClj793GCArzpqGqYHY6oIjZs+J2YmPH8808sXl7eDBhwExEREURESD0kYQ5HkkNd++RylfDd\nxoNk5hRwc89GeHvJA32EcyUlJTJ79lP897//B8A999zPlVf2NDkqIUpJDkqpP7XWHbDdBFf8kaEW\nwNBau92DZpPScvhx02FCA324tnNds8MRbu6zzz7miScmk5iYSIsWrViyZBmdO3cxOywhgNIf9tPB\n/neJ02ellK8zgzLL52v3k19gZfCVjfD1drvcJyqZkycTyM7OZubMuTzwwGi8vaV2l6g8HKnK+vtZ\n7z2w3RTnVo6cyGDd9uPUjqxG9zZSfVWUv+zsbJ5//lmys7MBuP/+B1m/fgtjxoyTxCAqndKGlX4B\netlfF59zKAC+dG5YFe/j1XsxDLitVxM8PKRUhihfv/yykilTHuPgwQMYhpVHH30MT09PatWSK+JE\n5VTasFIfAKXUc1rrRysupIoXeyCJv/cm0qJ+GG0ayd2novzExR1n+vSpfPHFp3h6ejJmzCOMGDHK\n7LCEuKDSeg79tdZfA38qpe45e73W+v+cGlkFsRoGH67aC8BtvRtLgT1Rbj777GMmTRpPenoanTpd\nzuLFy2jVqrXZYQnhkNIuZe0MfI19aOksBuAWyeGP2HgOxqXTtWUUDaKDzQ5HuJGoqGg8PT1YsuQ5\nhg27Fw8PuTRauI7ShpWesv89/NQypVQwtvsedlZAbE6XX2Dl09X78PK0MLhnI7PDES4uPT2NRYvm\nM3LkKOroWcNDAAAgAElEQVTXb0C3bj3488+dBAbKQ2eE63GkfMYIoDswBdgKpCulPtFaP+ns4Jzt\n1z+PcDI1h+s61yUy1N/scISLMgyDr776nGnTphAfH0dOTg6LFz8LIIlBuCxH+rljgEnAEOALoA3Q\n15lBVYTMnHy+Wn+AAF8v+ndrYHY4wkUdOLCfoUNvZeTIe0lJSSYm5gnmzFlgdlhCXDKHBkG11knA\njcA39kd9uvxp9re/28pk9OtWn0B/ucZclN0333xFz55d+PnnlfTs2ZvVq39n0qTH8fV1y3tERRXj\nSG2lnUqpr4FGwE9KqQ+BTc4Ny7kSU3NYufkIEcG+XNOxjtnhCBd12WUdqFmzFlOmTGPw4FvlSjfh\nVhzpOdwPLAK6aK3zgHeAkU6Nysk++20fBYVWBvdshLeXlMkQjklMTOTRR8fw668/A1CrVm3Wr9/C\nzTffJolBuB1HkoMP0B9YqZT6C+gDuGy/+VB8Or/viKNujUC6too2OxzhAqxWK++99w7dunXg/fff\n5Z133ipa5+kpJxfCPTmSHP4DBGDrQdwLeAMvOzMoZ/po1V4M4PbeTfCQsz1xAf/8E8ugQTcyfvzD\n5OXlM3v2fFaseNPssIRwOkfmHDpqrdsVez9WKbXLWQE50479iezcn0SrhuG0aihlMkTpfvttNXfc\nMZiCggL69RvI3LkLpRaSqDIc6Tl4KKVCT72xvy5wXkjOYTUMPvp1Lxbgtl6NzQ5HVGKGYXt8yeWX\nd+XKK6/i3Xc/4M0335XEIKoUR3oOzwCblFKnKrEOBOY7LyTn2LAzjsMnMujWOpp6UXJjkijp2LGj\nTJs2hY4dOzN27KP4+vrywQefmR2WEKa4YM9Ba/0mMBjYBxwAbtZav+HkuMpVfkEhn67Zh5enB4Ov\nlDIZ4kwFBQWsWLGc7t078803X7Jmza9FvQchqqrSqrJ6AA8DzYC1WusXKyyqcvbTliMkpeVyQ5d6\nRIT4mR2OqES2bt3CpEnj2b59G2FhYcyZ8x+GDBkml6aKKq+0nsNy4DYgE3hCKTWjYkIqXxnZ+Xy9\n/iDV/Lzod0V9s8MRlUhs7C769u3D9u3buOOOoaxbt4W77rpHqqcKQelzDlcBLbXWhlJqMfALMKti\nwio/X68/QHZuAXf2aUKAn5TJqOoMwyAnJwd/f39atGjJqFEPc/31N9C9+5VmhyZEpVLaKVKO1toA\n0FonYnuGg0tJSMnmlz+PUD3Ej94dpExGVbdv317uuGMwEyaMLVo2a9Y8SQxCnENpyeHsZGA951aV\n2Kdr9lFQaHDzVY3w9pKhgqoqNzeXpUsXctVVXVm16heSk5PIzc01OywhKrXShpXqK6XeON97rfX9\nzgvr0u0/nsbGXfHUjw7i8hZRZocjTLJ27RpiYiawZ8+/1KgRxdy5Cxk4cLBMOAtxAaUlh4lnvV/t\nzEDKk2EYfPTrHkDKZFRlJ06cYMiQW8jLy2PEiAeZOnU6wcEhZoclhEso7TGhb1dkIOVp+75E/jmU\nQtvGEbSoH2Z2OKICWa1WEhISiIqKokaNGixc+AwtW7aiffsOZocmhEtx5A5pl2K12stkWOBWKZNR\npezatZPJk8eTkZHBTz+twdvbm6FD7zY7LCFcktOSg/0muuVAOyAXGKm13nOO7VYASVrrx8vje9dt\nP87Rk5n0aFuTOpGB5bFLUcllZmayZMkCXn75PxQWFjJw4GCysjIJCQm98IeFEOfkUHJQSlUDGgPb\ngQCtdaYDHxsE+Gmtr1BKdQWWAjedtd9R2J5JXS7zGbn5hXz22z58vDwY1KNheexSVHJfffUVY8Y8\nzJEjh6lXrwELFizmmmuuNzssIVzeBa/vVEpdDWwDvgCigQNKqesc2HcP4HsArfUGoNNZ++0GdAFe\nKWPM57Vy02FSMvK4tnNdwoOlTIa7y8nJ4eGHHyY+Po7x4yexZs0GSQxClBNHeg7zsB3ov9NaH1dK\nXQW8D/x4gc8FA6nF3hcqpby01gVKqZrAU9gK+t3uaLCRkeevppqakct3Gw8RXM2Hu/u1opq/e98N\nXVpbuLOCggJ27dpF27ZtgSDeffddqlevTsuWLc0OrVKoqr8X5yJtcWkcSQ4eWus4pRQAWutdp15f\nQBpQ/F/HQ2t96jkQtwHVgW+x9UYClFL/aK3fKm2HCQnp513335W7yc4tYPCVTcnKyCErI8eRGF1S\nZGRQqW3hrjZv/oPJkydw5Mhh1q3bTI0aNejZsycJCelVsj3OVlV/L85F2uK0i02SjiSHI0qp/oBh\nf9DPw8AhBz63DhgAfGifc9h+aoXW+nngeQCl1H1A8wslhtLEJ2exautRaoT60+syeSCLu0lJSWbu\n3Fn83/+9gWEYDB16N97ebnehnRCViiP/w0YBzwF1sT3T4WfgQQc+9xlwrVJqPWABhiulhgKBWusV\nFxnvOX2yeh+FVoNbejXGy1PKZLgLwzD49NOPmD59KidPJqBUcxYvXkbXrt3MDk0It3fB5KC1PgEM\nKeuOtdZWYPRZi/85x3ZvlXXfxZ1MyWbzPydoWDOYTiryUnYlKqH33nuHzMwMnnxyJqNHj8XHx8fs\nkISoEi6YHJRS+zlHRVatdaV4pFrsoWQAurWOlno5biAnJ4ffflvFtdf2xWKxsHTp81gsFurXb2B2\naEJUKY4MK/Uq9tob2xVGvk6J5iLsPpwCQLO6csOTq1u9+lemTJnI/v37+Pbbn+jYsTMNGsj9KkKY\nwZFhpYNnLVqslNoMzHFOSGWz+3AKAb5e1I6sZnYo4iKdOHGCGTOm8umnH+Hh4cEDD4ymWTOHrogT\nQjiJI8NKPYu9tQCtAH+nRVQGSWk5JKTk0L5Jdam86qLeeectnn56OmlpqbRvfxlLljxH27btzQ5L\niCrPkWGlp4u9NoCTwL3OCadsZEjJ9e3erTEMg/nzl3DffSPw9PQ0OyQhBI4lhw+11i85PZKLcCo5\nqHqSHFxFRkYG7733f4wcORoPDw+mTJnG2LGPEhUVbXZoQohiHLkp4GGnR3GR9OEUfL09qRcl1Vdd\nwbfffk2PHp158snH+fjjDwAIDAyUxCBEJeRIz+GwUuoXYCOQfWqh1nqW06JyQFpmHscTs2jVMBxP\nD7nxrTI7fPgQ06bF8P333+Lt7c3EiTEMGDDI7LCEEKVwJDlsKPa60sz6ynyDa3j77Td46qknyMrK\nonv3K1m06FmaNm1mdlhCiAs4b3JQSt2rtX5ba/30+bYxU9F8gySHSs3Pzw9/f38WLnyG228fIjcq\nCuEiShuPebTCorgIuw+n4OXpQcOawWaHIopJTk5ixownSE21Je/bbx/Chg1bueOOoZIYhHAhLjlY\nn5WTz+ETGTSuFYy3l0v+CG7HMAw+/PB9unfvxMsv/4fXXrM9w8liscjjOoVwQaXNObRSSu07x3IL\nYJhZW+nfI6kYyHxDZbFnz7/ExExg7do1BAQEMGPGbEaNGmN2WEKIS1BactgD3FhRgZSFlvsbKo33\n3nuHmJgJ5OXlcf31NzBv3mLq1q1ndlhCiEtUWnLIO0ddpUph9+EUPD0sNK4VYnYoVV7r1m2Ijq7J\nrFnzueGGfjKvIISbKG3Afl2FRVEGOXkFHIxLp0F0EL4+UmqhosXHx/HQQyOJjd0FQNu27dmwYSs3\n3thfEoMQbuS8yUFrPbYiA3HU3mNpFFoNmW+oYIWFhbzxxqt069aJTz75kLfeeq1onZeXPLJTCHfj\ncv+r9SGZb6hof//9F5Mnj2fr1j8JDg5h0aJnufvu+8wOSwjhRC6XHHYfTsECNKktyaEifP75J4we\nPQKr1crNN9/G00/PIyoqyuywhBBO5lLJIb+gkH3H0qgbFUiAn0uF7lIMw/ZUWIvFQs+evejQoRNT\npkzjqqt6mxyZEKKiuNQdZMcTsygotNJIrlJymoMHD3DXXbfx5ZefARAeHsG33/4kiUGIKsalkkNK\nRh4AEcGV5hHWbiM/P5/nn3+Gnj278NNPP/LDD9+ZHZIQwkQuNTaTkpELQEg1SQ7lacOG34mJGc8/\n/8RSvXokS5c+zy233G52WEIIE7lUcki1J4fQIB+TI3Efa9as4tZbB2KxWLj33hFMmzaD0NAws8MS\nQpjMpZLDqWGlUOk5XBLDMCgoKMDb25vu3a/kjjuGcu+999Op0+VmhyaEqCRcbM7hVM9BksPF0vof\nBg26kcWL5wPg6enJCy+8LIlBCHEGl+o5pGbm4eVpoZpcxlpmWVlZLFu2hBdffI78/HwiI2tgGIaU\nvBBCnJNLHWVTMnIJqeYjB7Qy+uWXlcTEPMahQweoU6cu8+Ytpm/fSllwVwhRSbhMcrBaDVIz8mgQ\nHWR2KC5F63+4885b8PT05OGHH+Wxx6YQGBhodlhCiErOZZJDelYehVaDkECZb7iQwsJC0tPTCA0N\nQ6nmTJ8+iz59rqFVq9ZmhyaEcBEuMyGdlJYDQGigXMZamr/++pO+ffvw0EMji8pgjBs3XhKDEKJM\nXC45SM/h3NLSUpk6dRLXX9+bbdu2Eh4eQW5urtlhCSFclMsMKyVLz+GcDMPgyy8/48knHyc+Po4m\nTZqyaNGz9OjR0+zQhBAuzGWSQ2JRcpCeQ3GJiYmMHz+WgoJ8pkyZxtix4/H1lTYSQlwapyUHpZQH\nsBxoB+QCI7XWe4qtHwKMBwqA7cAYrbX1fPtLTrPfACfJgby8PPbt20OjRk2oXr06y5e/ilLNadSo\nsdmhCSHchDPnHAYBflrrK4DHgaWnViil/IE5QG+tdXcgBOhf2s5OzzlU7WGl9evX0r59e+6442ay\ns7MBuOGGfpIYhBDlypnDSj2A7wG01huUUp2KrcsFummts4rFkVPazpLScvDytNCwbjgeHlXvJriE\nhAQmT57M22+/jcViYcyYMYSF+RMUJPd9REZKG5wibXGatMWlcWZyCAZSi70vVEp5aa0L7MNH8QBK\nqXFAILCytJ0lpeUQXM2HxMQMpwVcGVmtVt5//11mzZpOcnIyrVu35fXXX6Vhwxbk5EBOTrrZIZoq\nMjKIhISq3QanSFucJm1x2sUmSWcmhzSgeFQeWuuCU2/scxKLgGbALVpro7SdJaflUi+q6t3ZW1BQ\nwPLlz5OXl8/s2fMZMWIUNWuGyS++EMKpnJkc1gEDgA+VUl2xTToX9wq24aVBpU1En1JQaCWkWtWY\nb8jMzGTbtq1069YDHx8fXn75DSIiIqhVq7bZoQkhqghnJofPgGuVUusBCzBcKTUU2xDSZmAE8Bvw\ni1IK4Dmt9Wel7bAqlOpeufJ7Hn98EidPJvDbb39Qr1592rRpa3ZYQogqxmnJwd4bGH3W4n+KvS7z\nlVKhbtxzOHbsKNOmTeGbb77Ey8uLMWMeoXr1SLPDEkJUUS5zExy4Z+kMwzBYsWI5CxbMJTMzgy5d\nrmDx4mU0b97C7NCEEFWYSyUHd7wBzmKxsGHD7/j4eDN37ovceeddeHi4TMkrIYSbcrHk4B7DSqmp\nKXz77dcMGTIMgAULluLp6Un16tVNjkwIIWxcJjlYLBAe7Gd2GJfEMAw+//wTpk+fyokT8dStW48e\nPXoSFRVldmhCCHEGl0kOT97fhUB/b7PDuGj79u1lypSJrF79K35+fjzxxAwuv7yr2WEJIcQ5uUxy\nuLxltMve+PXCC8tYtGguubm59OlzDQsWLKVBg4ZmhyWEEOflMsnBleXm5hAaGsbcuQsZMGAQFkvV\nqw0lhHAtclmMEyQkJDB37tPk5+cDMG7cBNat28TAgYMlMQghXIIkh3JktVp555236N69I889t5SP\nPvofAL6+vgQHh5gcnRBCOE6GlcrJzp07mDx5PJs3/0FgYBDz5y/mjjuGmh2WEEJcFEkO5eDFF59n\nzpynKCwsZODAwcyZs4Do6JpmhyWEEBdNkkM5aNy4CbVr12XhwiVcffV1ZocjhBCXTOYcLsKRI4d5\n6KGRnDhxAoC+fW9k3bpNkhiEEG5DkkMZ5Ofns3z5C/TocTmffPIh7777VtE6X1/3q/skhKi6ZFjJ\nQZs3/8GkSePZtWsH4eHhLFiwRCachRBuS3oODnj99RX063ctu3bt4K677mH9+i3ceeddcs+CEMJt\nSc/BAb169aZt2/bMnr2Arl2vMDscIYRwOuk5nMOePf9y6603sWnTRgAaN27Kjz+uksQghKgyJDkU\nk5OTw8KFc+nV6wrWrPmVL7/8vGidDCEJIaoSGVayW736V2JiJrB//z6io2syd+4i+vcfaHZYQlSI\nP//czIwZU2nQoCEWi4XMzExq1arNU0/Nwdvbm+TkZF58cRlxccexWq3UqBHFuHETiIiwPaBq27at\nvPnmqxQUFJCTk8ONNw7g5ptvM/VnSk1N4ZVXXiQmZpqpceTm5jBr1nSSk5MJCAhg2rSnCQsLO2Ob\n999/l5Urv8fDw4O77x7OVVf1xjAMBg++kTp16gLQunVbRo8ey+uvv0KfPtfSsGEjp8YtyQH4+OMP\nGDPmATw8PBg1agxTpkwjMDDI7LBEFfXhL3vY9M+JMn/O09NCYaFxznWdm9fg9j5NSv18x46dePrp\n+UXvZ86cxtq1q+nV62qmTZvMkCHDuPLKXgBs2rSRmJgJrFjxFnFxx1m2bDFLl75AeHgEubk5jBs3\nmlq1atO1a7cy/xzl5dVXX+Lmm2837ftP+eyzj2nUqAkjRozip59+4O23X2f8+ElF69PT0/noo/f5\n4IPPyc7OZvjwoVx1VW+OHj1Cs2bNWbTo2TP2d/vtQ3n66WksWfK8U+OussnBarUC4OHhQd++/bjx\nxgE89lgMbdq0MzkyIcyXn59PYuJJgoKC0TqWwMDAosQA0LlzF7766nO2bdvKX3/9Sd++/QgPjwDA\n19ePZ575D/7+/mfs8/DhQyxcOIf8/Hz8/PyYOXMey5c/x9VXX0fXrt3YsGE9P//8I9OmzeSWW/pT\nv34DGjRoyLp1v/HWW+/j7+/Pe++9g6enB716Xc2iRfPIzc3B19ePmJgniIqKLvqujIwMYmN3MWlS\nUwA++eQDVq/+lezsbEJDQ5k3bwkrV37PN998idVqZcSIUaSlpfHBB//Fw8ODtm3b89BD4zhxIp4l\nSxaQl5dLYuJJHnhgDD17nm6HI0cOs2DB7DN+zmuv7ctNN91c9P7vv7cxdOg9AHTt2p233nr9jO39\n/f2Jjq5JdnY2OTnZRc+Q1zqWkydPMG7cKHx9fXnkkYnUq9eAoKAgfH192bPnX5o0aXqR/8IXViWT\nw/btfxMTM54hQ+7mnnuGExgYyFtv/dfssIQA4PY+TS54ln8ukZFBl/RArC1bNjN27IOkpCRjsVgY\nOPBmOnW6nJ9/XkmtWnVKbF+rVm3i4o5z8mQCTZs2O2NdYGBgie1ffHEZw4bdR9eu3Vi7djX//qvP\nG8uJE/G88ca7hISE4uXlzapVP3PDDf356afvefbZF1m6dCG33noHV1zRnc2b/+Dll//DU0/NKfr8\nX3/9Rb169QHbiWBqairLli3Hw8ODiRPHEhu7E4CgoCAWLHiGtLRUxowZyWuvvYOfnx+zZ09n06YN\ngIU777yLDh06sX37Nl5//ZUzkkOdOnX5z39WlNqumZmZRe0REBBAZmZGiW1q1Iji7rtvo7DQyt13\n3wdARER1hg0bTp8+17Bt21/MmjWD1177P8B2kczWrVskOZSXjIx0Fi6cx6uvvoTVaqV1a+klCHHK\nqWGl1NQUJkx4mJo1awEQGRlJXNyxEtsfOXKIzp27cPJkAidOxJ+x7t9/d2MYVpo1a1607NChg7Ru\n3RaAHj2uAmDlyu+L1hvG6SGxkJBQQkJCARgwYBBLliygfv0G1K1bn5CQUPbt28M777zJf//7NgCe\nnmceypKTkwkPDwdsowPe3t7MnDkNf39/Tpw4QUFBAUBRAjly5DApKclMmvQIAFlZWRw9eoS2bS/j\n7bdf55tvvgAsRZ873QYX7jlUq1aNrKzMov2enTg3bFhHYuJJPvzwSwAee2wcbdq0o3nzlnh6egLQ\nrl17Tp5MwDAMLBYLERHVOXkyAWeqEsnBMAy+/fZrpk2L4dixozRo0JCFC5+hd++rzQ5NiEonJCSU\n6dNn88gjo2ne/D3atGlHYmIia9euoUePngBs2LCeI0eO0L59B2rVqs3UqZPo0+c6wsLCyMrKYvHi\neQwfPvKM/dav35DY2J107tyFH3/8jrS0VHx8fEhMPAnA7t3/FG17amgFoG7deoDBe++9w+DBtwJQ\nr14DhgwZRps27Th48ABbt24547siIiJIT7f1ovbs+Zc1a1bx6qtvk5OTw4gRw4q2s1hs31OzZm1q\n1Ihi2bLleHl58e23X9G0aTNee+1lBgwYxBVXdOebb77ku+++PuN7HOk5tGnTjt9/X0fLlq3ZsGEd\n7dpddsb6oKBgfH198fHxwWKxEBgYSEZGBm+8sYKQkBDuuute/v13NzVqRBVdNZmenkZoaNi5vq7c\nVInk8Ntvqxk+/C68vb2ZODGGRx99rMR4qBDitIYNG3HrrXewbNli5sxZyKJFz/Lcc0t55503Adsw\nyOLFy/D09KRmzVqMGfMI06ZNxsPDg6ysLPsBtccZ+3z44UdZvHgeb7/9On5+fsyYMZtjx44yf/4s\nfvzxe3sSOLd+/W7i9ddfpkOHTkX7Wrp0AXl5eeTm5vDoo5PO2L5du3bMn78QsB3A/f39eeih+wHO\nedYdFhbGHXfcxdixD1JYWEjNmrXo0+daeve+mhdffI53332LyMgapKSklLktBw++lTlznuKhh0bg\n7e1dNPz1v/+9S506denR4yo2b/6DBx+8r2i+o3PnLjRv3pLZs6fz++/r8PT0ZNq0mUX73LVrJ6NG\nPVzmWMrCUrwrV8kZZRlPzc/PJy8vj2rVqmEYBrNnP8WQIcNKjI26oksdW3Yn0hanSVucFhkZREzM\nVG666eYzhrbcQVpaKnPmzCxxFdP5REYGXdRNWm55E9zGjRu45porefrpJwHbDWwzZsxyi8QghHDM\nyJGj+eyzj80Oo9x98MF7Tu81gJslh+TkJCZOHMeAAdcRG7sLwzhzkksIUXWEhYUzZcqTZodR7h54\n4CEaNy771Wxl5RZzDoZh8OGH7zNz5jQSExNp0aIVixcv4/LLu5gdmhBCuCS3SA579+7h0UfH4Ofn\nx1NPzeHBBx/C29vb7LCEEMJluWxyyM7OJjk5iVq1atOkSVOWLXuR7t2vLPWKByGEEI5xyTmHX375\niZ49u/DAA/cVlcG48867JDEIIUQ5cVrPQSnlASwH2gG5wEit9Z5i6wcAM4AC4A2t9asX2md8fBzT\npz/O559/iqenJzfeOID8/Hx5frMQQpQzZ/YcBgF+WusrgMeBpadWKKW8gWeB64CrgAeVUlGl7ezF\nF1+kW7dOfP75p3Ts2JmVK9fw9NNzJTEIIYQTODM59AC+B9BabwA6FVvXAtijtU7WWucBa4Gepe1s\n5syZeHh4sHjxMr75ZiWtW7dxVtxCCFHlOXNCOhhILfa+UCnlpbUuOMe6dCCktJ0lJCTIo9iKiYyU\n502cIm1xmrTFadIWl8aZPYc0oPi/joc9MZxrXRBQ9qIlQgghnMKZyWEdcCOAUqorsL3YuligqVIq\nXCnlg21I6XcnxiKEEKIMnFZ4r9jVSm0BCzAc6AAEaq1XFLtayQPb1UovOiUQIYQQZeZKVVmFEEJU\nEJe8CU4IIYRzSXIQQghRgiQHIYQQJVS6wnvOKLvhqhxoiyHAeGxtsR0Yo7W2mhGrM12oHYpttwJI\n0lo/XsEhVhgHfic6A89guwgkDhimtc4xI1Znc6At7gIeAwqxHSteMiXQCqSU6gIs1Fr3Omt5mY+b\nlbHnUK5lN1xcaW3hD8wBemutu2O7ibC/KVE633nb4RSl1CigKtw2X9rvhAV4FRiutT5VoaC+KVFW\njAv9XiwBrgG6A48ppcIqOL4KpZSKAV4D/M5aflHHzcqYHMq17IaLK60tcoFuWuss+3svwC3PECm9\nHVBKdQO6AK9UfGgVrrS2aAYkAhOUUquBcK21rvgQK0ypvxfA39hOmvyw9aTc/dLMvcDN51h+UcfN\nypgczll24zzrLlh2w8Wdty201latdTyAUmocEAisrPgQK8R520EpVRN4ChhrRmAmKO3/R3WgG/Af\nbGfMVyul+lRwfBWptLYA2AFsAXYCX2ut3boKg9b6EyD/HKsu6rhZGZODlN04rbS2QCnloZRaAlwL\n3KK1dtczo9La4TZsB8VvsQ0tDFVK3Vex4VWo0toiEdsZYqzWOh/bWfXZZ9Pu5LxtoZRqC/QDGgIN\ngBpKqdsqPMLK4aKOm5UxOUjZjdNKawuwDaP4AYOKDS+5o/O2g9b6ea11R/sE3ALgPa31W2YEWUFK\n+53YBwQqpU49ff5KbGfN7qq0tkgFsoFsrXUhcAJw6zmHUlzUcbPS3SEtZTdOK60tgM32P79xeiz1\nOa31ZyaE6lQX+p0ott19QPMqcrXS+f5/9MGWJC3Aeq31o6YF62QOtMVo4H4gD9t4/AP2MXe3pZRq\nAPxPa91VKTWUSzhuVrrkIIQQwnyVcVhJCCGEySQ5CCGEKEGSgxBCiBIkOQghhChBkoMQQogSKl3h\nPVE12S/B2w3sOmvVAK314fN8ZiaA1nrmJXzvfdgK1R2yL/IHVmMrYlhwvs+dZ1+zgM1a6y+VUr9q\nrXvbl/+ltW5/sTHa97EKqANk2BcFY7uv4a5Td8qf53MPAula6/cv5ftF1SPJQVQmxy71IHqRvtRa\n3weglPIEVgEPA8+VZSda6xnF3vYqtry8fqaRWutVUHSN/8fARGBKKZ/phu3nEaJMJDmISk8p1Rp4\nAdvNfzWApVrr54ut9wbeAFrbFy3XWr9qrzz5ClAXsAJTtdY/lfZdWutCpdR6bEXsUEoNx1b22cBW\np2cstqKH5/q+t7AdiDvYP7tRa91FKWUA3th6J5dpreOVUuHYav/UB64GZtm32Y/tZq3ECzRLNWxl\nQ3tGQ8cAAAMBSURBVDbav+s2e5z+9j8jAR9gINBHKXUc+Kus7SGqLplzEJVJLaXUX8X+TLYvHwnM\n0Vp3BnoDc8/6XDdsFUgv43SJZrCd+b+hte6I7SD5ilIqiFIopSKAG4B1Sqk2wDTgKq11GyATW5G/\n830fAFrrR+x/dym2rAD4CFstKIBbgM+BUGx3NF9v398PwMLzhPeaUmqb/UC/AVuhxWftvYjRQH+t\ndTv7/ibbD/xfAjO01j9cTHuIqkt6DqIyOd+w0mNAX6XUVGylEgLPWr8DUEqpH7AV4Ds1zHIN0Nw+\nFwC2M/PG2M6gixuolPoLWwkGD+BT4H1sQ0tfFTuLXwG8ie3ge67vu5B3gGXYqqYOAZ7EVmq8HvCr\nUgrAk/9v745dowiiOI5/RQtJaSmm9QdamEbQTgIiCiYEUtjYJSCCNnaiaKWFYOGfIBFiIIEQjI2E\nGEIgUQ5NEPI6SxtjYZUmWLxZWbOXYyXVkd+nuRvubmduins78443sHPA5yciYrmUKJ8FFqtyEJLG\ngJvKi1whD7jZr+18mDk4WF+YAX4BC8A0cKv+YkT8lHSerE57A+iU9nFgOCJ2ACSdBrolb//mHOrK\nHXndMeBEj/56iojPpfjZReBMRKxJGgVWI2Kk9HmSfytodrvOmqRXwGtJF8jii5/I4LNCnmPQrYR5\n2/kw87aS9YWr5NbIPHmSVZU4pjwfAaaAd8B98h89g8AScLe85xz5oznwH/0uk6uKU6U9Sd7hH9Rf\n3f6zBSpvyH3/6dJeBy5LOlvaj4EXLcb2ksw73CHzI3vAM/I7XycDAeSxkNU4DjsfdoQ4OFg/eAqs\nSuoA14DvZJ3+ynuyPPM3YAOYi4gt4B5wSdIm8Ba4HRG/23YaEZvAc+CjpG0yP/CoR39188DXshKo\nmwKGyiMR8YOsHDojaYtMZj9oMbZdMh/yhKw4+gXYBjpksKqOB/0APJQ0ziHnw44WV2U1M7MGrxzM\nzKzBwcHMzBocHMzMrMHBwczMGhwczMyswcHBzMwaHBzMzKzhD9wC1M7DawBAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d0d85c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    " \n",
    "# shuffle and split training and test sets\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size=.25)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "#clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'gini')\n",
    "#rf_clf = clf.fit(X_train,Y_train)\n",
    "#rf_predict = rf_clf.predict(X_test)\n",
    "\n",
    "forest.fit(X_train, Y_train)\n",
    " \n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, forest.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.72%\n",
      "XG Boost:\n",
      "Accuracy          F-score\n",
      "0.831032005747  -  0.831032005747\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(model, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(model, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"XG Boost:\")\n",
    "print(\"Accuracy\"+\"          \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#xgb_clf = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train,Y_train)\n",
    "#xgb_predict= xgb_clf.predict(X_test)\n",
    "#xgb_acc = accuracy_score(Y_test,xgb_predict)\n",
    "#accuracy = cross_val_score(xgb, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "#f_score = cross_val_score(xgb, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "#print(\"XG Boost:\")\n",
    "#print (accuracy.mean(), \" - \",f_score.mean())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.27%\n",
      "Voting Classifier:\n",
      "Accuracy        F-score\n",
      "0.799638837896  -  0.799616888818\n"
     ]
    }
   ],
   "source": [
    "#Trying the VotingClassifier: tries to concetually combine different machine learning classifiers and use a majority\n",
    "#vote to predict the labels.Such a classifier for a set of equally well performing classifiers in order to balance out\n",
    "#their individual weaknesses.\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "\n",
    "\n",
    "clf1 = clf1.fit(X_train, Y_train)\n",
    "clf2 = clf2.fit(X_train, Y_train)\n",
    "clf3 = clf3.fit(X_train, Y_train)\n",
    "eclf = eclf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = eclf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Voting Classifier:\")\n",
    "print(\"Accuracy\"+\"        \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.72%\n",
      "XG Boost:\n",
      "Accuracy          F-score\n",
      "0.831032005747  -  0.831032005747\n",
      "ROC AUC: 0.86\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1216bce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(model, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(model, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"XG Boost:\")\n",
    "print(\"Accuracy\"+\"          \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "\n",
    "\n",
    "\n",
    "#forest.fit(X_train, Y_train)\n",
    " \n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.27%\n",
      "Voting Classifier:\n",
      "Accuracy        F-score\n",
      "0.799616888818  -  0.799616888818\n",
      "ROC AUC: 0.86\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1217282b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "\n",
    "\n",
    "clf1 = clf1.fit(X_train, Y_train)\n",
    "clf2 = clf2.fit(X_train, Y_train)\n",
    "clf3 = clf3.fit(X_train, Y_train)\n",
    "eclf = eclf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = eclf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Voting Classifier:\")\n",
    "print(\"Accuracy\"+\"        \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_test, eclf.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(model, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(model, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"XG Boost:\")\n",
    "print(\"Accuracy\"+\"          \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
