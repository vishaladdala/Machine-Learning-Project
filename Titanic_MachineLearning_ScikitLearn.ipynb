{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sys,os\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ross, Mr. John Hugo</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13049</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>A10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Minahan, Dr. William Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19928</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hakkarainen, Mr. Pekka Pietari</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101279</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yasbeck, Mr. Antoni</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Perreault, Miss. Anne</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12749</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>B73</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yousif, Mr. Wazli</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2647</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Mi...</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 33595</td>\n",
       "      <td>15.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347060</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Mrs. Catherine (Catherine Rizk)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Taussig, Mrs. Emil (Tillie Mandelbaum)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110413</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>E67</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Stranden, Mr. Juho</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101288</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sedgwick, Mr. Charles Frederick Waddington</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244361</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "583          584         0       1   \n",
       "885          886         0       3   \n",
       "881          882         0       3   \n",
       "245          246         0       1   \n",
       "403          404         0       3   \n",
       "620          621         0       3   \n",
       "520          521         1       1   \n",
       "354          355         0       3   \n",
       "161          162         1       2   \n",
       "851          852         0       3   \n",
       "533          534         1       3   \n",
       "558          559         1       1   \n",
       "744          745         1       3   \n",
       "343          344         0       2   \n",
       "873          874         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "583                                Ross, Mr. John Hugo    male  36.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "245                        Minahan, Dr. William Edward    male  44.0      2   \n",
       "403                     Hakkarainen, Mr. Pekka Pietari    male  28.0      1   \n",
       "620                                Yasbeck, Mr. Antoni    male  27.0      1   \n",
       "520                              Perreault, Miss. Anne  female  30.0      0   \n",
       "354                                  Yousif, Mr. Wazli    male   NaN      0   \n",
       "161  Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Mi...  female  40.0      0   \n",
       "851                                Svensson, Mr. Johan    male  74.0      0   \n",
       "533             Peter, Mrs. Catherine (Catherine Rizk)  female   NaN      0   \n",
       "558             Taussig, Mrs. Emil (Tillie Mandelbaum)  female  39.0      1   \n",
       "744                                 Stranden, Mr. Juho    male  31.0      0   \n",
       "343         Sedgwick, Mr. Charles Frederick Waddington    male  25.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "\n",
       "     Parch             Ticket     Fare Cabin Embarked  \n",
       "583      0              13049  40.1250   A10        C  \n",
       "885      5             382652  29.1250   NaN        Q  \n",
       "881      0             349257   7.8958   NaN        S  \n",
       "245      0              19928  90.0000   C78        Q  \n",
       "403      0   STON/O2. 3101279  15.8500   NaN        S  \n",
       "620      0               2659  14.4542   NaN        C  \n",
       "520      0              12749  93.5000   B73        S  \n",
       "354      0               2647   7.2250   NaN        C  \n",
       "161      0         C.A. 33595  15.7500   NaN        S  \n",
       "851      0             347060   7.7750   NaN        S  \n",
       "533      2               2668  22.3583   NaN        C  \n",
       "558      1             110413  79.6500   E67        S  \n",
       "744      0  STON/O 2. 3101288   7.9250   NaN        S  \n",
       "343      0             244361  13.0000   NaN        S  \n",
       "873      0             345765   9.0000   NaN        S  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in data\n",
    "training_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/train.csv\")\n",
    "training_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data statistics using .describe()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert ages to bins called 'Unknown'for [-1,0], 'Baby' for [0-5],\n",
    "#'Child' for [6-12], 'Teenager' for [13-19], 'Student' for [20-25], 'Young Adult' for [26-35], 'Adult' for [36-60],\n",
    "#'Senior' for [61-100]\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 19, 25, 35, 60, 100)\n",
    "    age_groups = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=age_groups)\n",
    "    df.Age = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method which simplifies the cabin feature by filling N/A values with 'N'\n",
    "#also it takes only the first letter the cabin using splicing\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert fares into bins using the numbers from .describe() statistics earlier\n",
    "#the N/A values are filled with -0.5\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Extraction \n",
    "#the below method is used to extract two features from the Name column\n",
    "#method to format the Name column to extract LName and NamePrefix\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to drop the features which we inconsider inconsequential\n",
    "#we have selected ticket,Name,Embarked columns to be dropped due lack of variance or too many N/A values\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method calls all the above transformation methods one by one and applies it on our dataframe\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to proceed to apply the transformations on the training data\n",
    "transformed_train = transform_features(training_data)\n",
    "transformed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as we can see above our training data now has :\n",
    "#1. LName, NamePrefix instead of 'Name' which has been dropped\n",
    "#2. 'Ticket', 'Name', 'Embarked' have been dropped \n",
    "#3. 'Fare', 'Age' have been converted into convenient bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now as a next step, we need to remember that machine learning algorithms need all the input to be numerical values\n",
    "#But as we can observe from above 'Sex', 'Age' , 'Fare', 'Cabin', 'Lname', 'NamePrefix' are in nominal(string) format\n",
    "#Hence we need to convert these into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>251</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7     73   \n",
       "1            2         1       1    0    0      1      0     3      2    136   \n",
       "2            3         1       3    0    7      0      0     0      7    251   \n",
       "3            4         1       1    0    7      1      0     3      2    198   \n",
       "4            5         0       3    1    7      0      0     1      7     11   \n",
       "\n",
       "   NamePrefix  \n",
       "0          17  \n",
       "1          18  \n",
       "2          14  \n",
       "3          18  \n",
       "4          17  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we proceed to use LabelEncoder from sklearn preprocessing to achieve \n",
    "#Every column in numerical form\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "    return df_train\n",
    "    \n",
    "data_train = encode_features(transformed_train)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we proceed to test the various classifiers in Scikit-Learn to \n",
    "#see which classifiers works best on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "#Below we are splitting up our training data into 80% training , 20% testing data \n",
    "# X contains all the columns except 'Survived' because that is the feature we predict\n",
    "# Y consists only of the column 'Survived'\n",
    "X = data_train.drop(['Survived'], axis=1)\n",
    "Y = data_train.Survived\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 14]\n",
      " [24 44]]\n",
      "0.787709497207\n"
     ]
    }
   ],
   "source": [
    "#Our first classifier will be Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifiers = {}\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "classifiers[\"Decision Tree\"]=dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.531305611446  -  0.592749832327\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.559239883747  -  0.516724793204\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DeepNeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.618025933378  -  0.618025933378\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SupportVectorMachine\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.53073384753  -  0.53073384753\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"MultinomialNaiveBayes\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.714366756092  -  0.714366756092\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LogisticRegression\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.565828303152  -  0.565828303152\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.832689470154  -  0.831241895819\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 500, max_depth = 100)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RandomForest\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.802991281019  -  0.802991281019\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 0.5)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"AdaBoost\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.825688016991  -  0.822791191594\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 100,learning_rate = 0.25)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GradientBoostingClassifier\"]=clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.55364017438  -  0.55364017438\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"Perceptron\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "Decision Tree\n",
      " :  0.760692488263    0.753827967807\n",
      "NeuralNetwork\n",
      " :  0.512438520009    0.53620780237\n",
      "DeepNeuralNetwork\n",
      " :  0.531324055444    0.588330538788\n",
      "SupportVectorMachine\n",
      " :  0.618025933378    0.618025933378\n",
      "MultinomialNaiveBayes\n",
      " :  0.53073384753    0.53073384753\n",
      "LogisticRegression\n",
      " :  0.714366756092    0.714366756092\n",
      "KNN\n",
      " :  0.565828303152    0.565828303152\n",
      "RandomForest\n",
      " :  0.829813324391    0.833960429242\n",
      "AdaBoost\n",
      " :  0.802991281019    0.802991281019\n",
      "GradientBoostingClassifier\n",
      " :  0.829913369104    0.822851553767\n",
      "Perceptron\n",
      " :  0.55364017438    0.55364017438\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hence we see that Random forest classifier gave the best performance with an accuracy ~83% and an F-score ~83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next we proceed to apply \"Feature Scaling\" to see if the performance of our various classifiers improves\n",
    "#Feature scaling aims to bring the values of our numerical features between 0 and 1\n",
    "#This is mainly done because large numerical values may skew our data and make the classifier weight it more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this technique is known to improve the performance of classifiers using gradient descent such as neural nets,perceptron,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = data_train.drop(['Survived'], axis=1)\n",
    "YY = data_train.Survived\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "XX[XX.columns] = scaler.fit_transform(XX[XX.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.110606</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.380303</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.110606   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.206061   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.380303   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.300000   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.016667   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.566667  \n",
       "1    0.600000  \n",
       "2    0.466667  \n",
       "3    0.600000  \n",
       "4    0.566667  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we run the classifiers again after performing feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 14]\n",
      " [21 47]]\n",
      "0.804469273743\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifiers = {}\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "classifiers[\"Decision Tree\"]=dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.794440532081  -  0.78890509725\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.794659065504  -  0.779163313213\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DeepNeuralNetwork\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.79598759222  -  0.79598759222\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SupportVectorMachine\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.73565448245  -  0.73565448245\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"MultinomialNaiveBayes\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.79590878605  -  0.79590878605\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LogisticRegression\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.779065504136  -  0.779065504136\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.834019673597  -  0.833939749609\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 500, max_depth = 100)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RandomForest\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.802991281019  -  0.802991281019\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 0.5)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"AdaBoost\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.82564889336  -  0.828405432596\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 100,learning_rate = 0.25)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GradientBoostingClassifier\"]=clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.711349765258  -  0.711349765258\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"Perceptron\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.59%\n",
      "XG Boost:\n",
      "Accuracy          F-score\n",
      "0.815669572994  -  0.815669572994\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"XG Boost:\")\n",
    "print(\"Accuracy\"+\"          \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"XGBoost\"]=clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.56%\n",
      "Voting Classifier:\n",
      "Accuracy        F-score\n",
      "0.787516208361  -  0.787516208361\n"
     ]
    }
   ],
   "source": [
    "#Trying the VotingClassifier: tries to concetually combine different machine learning classifiers and use a majority\n",
    "#vote to predict the labels.Such a classifier for a set of equally well performing classifiers in order to balance out\n",
    "#their individual weaknesses.\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "\n",
    "\n",
    "clf1 = clf1.fit(X_train, Y_train)\n",
    "clf2 = clf2.fit(X_train, Y_train)\n",
    "clf3 = clf3.fit(X_train, Y_train)\n",
    "eclf = eclf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = eclf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(eclf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Voting Classifier:\")\n",
    "print(\"Accuracy\"+\"        \"+\"F-score\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"VotingClassifier\"]=eclf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "Decision Tree\n",
      " :  0.745356583948    0.755076570534\n",
      "NeuralNetwork\n",
      " :  0.791861725911    0.787595573441\n",
      "DeepNeuralNetwork\n",
      " :  0.803170690812    0.78890509725\n",
      "SupportVectorMachine\n",
      " :  0.79598759222    0.79598759222\n",
      "MultinomialNaiveBayes\n",
      " :  0.73565448245    0.73565448245\n",
      "LogisticRegression\n",
      " :  0.79590878605    0.79590878605\n",
      "KNN\n",
      " :  0.779065504136    0.779065504136\n",
      "RandomForest\n",
      " :  0.835388441762    0.821362061256\n",
      "GradientBoostingClassifier\n",
      " :  0.821363179074    0.824240442656\n",
      "AdaBoost\n",
      " :  0.802991281019    0.802991281019\n",
      "Perceptron\n",
      " :  0.711349765258    0.711349765258\n",
      "XGBoost\n",
      " :  0.815669572994    0.815669572994\n",
      "VotingClassifier\n",
      " :  0.787516208361    0.787516208361\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So from our results we can see that our best performing classifiers are:\n",
    "#1)RandomForest:  0.835388441762    0.821362061256\n",
    "#2)GradientBoostingClassifier:  0.821363179074    0.824240442656\n",
    "#3)XGBoost:  0.815669572994    0.815669572994\n",
    "#4)DeepNeuralNetwork:  0.803170690812    0.78890509725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next step is to tune the hyperparameters of our best performing classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 13.23 seconds for 100 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.824 (std: 0.029)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'min_samples_leaf': 2, 'min_samples_split': 8}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.823 (std: 0.021)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.822 (std: 0.027)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 7}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.822 (std: 0.029)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 4, 'min_samples_leaf': 4, 'min_samples_split': 7}\n",
      "\n",
      "GridSearchCV took 95.87 seconds for 768 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.829 (std: 0.027)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.827 (std: 0.016)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.827 (std: 0.018)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.827 (std: 0.036)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.827 (std: 0.028)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Hyperparameter tuning\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [10,3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 100\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3,10,100, None],\n",
    "              \"max_features\": [1, 3,7,10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10,100],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV took 95.87 seconds for 768 candidate parameter settings.\n",
    "Model with rank: 1\n",
    "Mean validation score: 0.829 (std: 0.027)\n",
    "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoost Classifier Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 68.42 seconds for 1536 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.037)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.815 (std: 0.033)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'nthread':[1,2,3,4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.01,0.05], #so called `eta` value\n",
    "              'max_depth': [6,8,10,100],\n",
    "              'min_child_weight': [5,10,11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.3,0.7],\n",
    "              'n_estimators': [5,10,20,100], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [27,1337]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV took 68.42 seconds for 1536 candidate parameter settings.\n",
    "Model with rank: 1\n",
    "Mean validation score: 0.815 (std: 0.037)\n",
    "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 100, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 1108.53 seconds for 41472 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.046)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 0, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.024)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.049)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': -999, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 100, 'silent': 2, 'subsample': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 2, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 3, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 1, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.808 (std: 0.041)\n",
      "Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 100, 'min_child_weight': 5, 'missing': 1, 'n_estimators': 20, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 27, 'silent': 2, 'subsample': 0.8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'nthread':[1,2,3,4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.01,0.05,0.1], #so called `eta` value\n",
    "              'max_depth': [6,8,10,100],\n",
    "              'min_child_weight': [5,10,11,100],\n",
    "              'silent': [1,2],\n",
    "              'subsample': [0.8,0.6],\n",
    "              'colsample_bytree': [0.3,0.7],\n",
    "              'n_estimators': [5,10,20], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999,0,1],\n",
    "              'seed': [27,1337,100]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with rank: 1\n",
    "Mean validation score: 0.808 (std: 0.041)\n",
    "Parameters: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10, 'missing': -999, 'n_estimators': 20, 'nthread': 1, 'objective': 'binary:logistic', 'seed': 100, 'silent': 1, 'subsample': 0.8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 24.35 seconds for 150 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.830 (std: 0.011)\n",
      "Parameters: {'max_depth': 14, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.8}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.829 (std: 0.020)\n",
      "Parameters: {'max_depth': 8, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.827 (std: 0.024)\n",
      "Parameters: {'max_depth': 14, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.85}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'max_depth':range(6,16,2),\n",
    "              'min_samples_split':range(100,999,150),\n",
    "              'min_samples_leaf':range(20,77,100),\n",
    "              'max_features':range(7,20,100),\n",
    "              'subsample':[0.6,0.75,0.8,0.85,0.9]}\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with rank: 1\n",
    "Mean validation score: 0.830 (std: 0.011)\n",
    "Parameters: {'max_depth': 14, 'max_features': 7, 'min_samples_leaf': 20, 'min_samples_split': 100, 'subsample': 0.8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plotting ROC curves for our best classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112c4af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ROC Curve for Random Forest Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    " \n",
    "# shuffle and split training and test sets\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size=.25)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "#clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'gini')\n",
    "#rf_clf = clf.fit(X_train,Y_train)\n",
    "#rf_predict = rf_clf.predict(X_test)\n",
    "\n",
    "forest.fit(X_train, Y_train)\n",
    " \n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, forest.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.89\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQohMJDkIIYTI5P9Ukm/fQHQ4/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d2e198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112bf1b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
